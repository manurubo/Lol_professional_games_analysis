---
title: "Practica 2. Tipología y ciclo de vida de los datos."
subtitle: "Lol professional games analysis"
author: "Manuel Ruiz Botella"
date: "3 de Enero de 2021"
output:
  pdf_document:
    toc: true
    toc_depth: 5
  html_document: default
mainfont : TimesNewRoman
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE,}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
require(dplyr)
require(kableExtra)
require(VIM)
require(mltools)
require(data.table)
require(ggplot2)
require(heplots)

```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# 1. Descripción del dataset. 

El dataset es un conjunto de partidas de League of Legends profesional, concretamente contiene los datos que se generan en cada mapa por parte de los jugadores de los equipos y los equipos. Las partidas del dataset pertenecen a los torneos LEC, LCS y WORLDS de 2020. 

El dataset se encuentra en: https://zenodo.org/record/4265268#.X--muthKhPZ

Para cada partida se recogen todo tipo de variables, desde el resultado del mapa, los equipos que lo juegan, los campeones utilizados, los jugadores de cada equipo, una gran cantidad de estadísticas del juego, etc. Algunas de las variables son básicas como el Oro final de un jugador, y otras derivadas como el oro por minuto. En total hay más de 500 variables, entre aquellas que son específicas de jugadores y aquellas que hacen referencia a un evento de la partida como la primera sangre o el número de dragones. Además, con las variables actuales es posible generar más variables al procesar los datos en función del objetivo.

## 1.1 ¿Por qué es importante y qué pregunta/problema pretende responder?

El dataset es importante porqué apenas hay datasets con tantos datos de partidas profesionales de manera abierta. Además, este dataset nos puede permitir identificar aspectos importantes de que influyen en la victoria de un equipo, predecir variables de la partida o el equipo vencedor, identificar debilidades de un equipo, que jugador es mejor en su posición, etc.

Este estudio va a estar enfocado a resolver problemas que tienen relación con la victoria de un equipo o otro, como son:

* Identificar las variables relacionadas con la victoria de un equipo.
* Describir las variables relacionadas con la vicoria de un equipo.
* Identificar diferencias en variables relacionadas con la victoria de un equipo. 
* **Identificar como influyen los factores importantes en la victoria.** 
* **Identificar que equipo va a ganar una partida.**

Por tanto, todos los análisis y tratamiento de datos van a estar centrados en que la finalidad es poder identificar el equipo de ganador, y que esto tiene que estar representado como la variable objetivo en el dataset. 

## 1.2 Descripción del dataset por código

Es importante mencionar que se guarda el dataset de datos recien cargado en el dataset lol_base. El objetivo es que podamos estudiar los datos sin transformar ni seleccionar en siguientes pasos del dataset. 


```{r,eval=TRUE,echo=TRUE}

fichero <- paste(getwd(),'../Data/Input/Lol_ProfessionalGames.csv', sep='/')
fichero
lol <- read.csv2(fichero,sep=',')
lol_base<- lol

# Comprobar que los datos se han cargado en el dataframe correctamente
str(lol)

# Comprobar que las dimensiones del dataframe son correctas, 614 filasx517columnas
dim(lol)

# Comprobar los tipos de las variables
sapply(lol,class)


```

Al estudiar los tipos de datos de las variables y que estas están bien cargadas, hemos visto que hay muchísimas variables. 
Hay variables que hacen referencia a una misma estadística de la partida, pero cambia el equipo al que hace referencia o el jugador del equipo al que hace referencia, por ejemplo, kills_top_azul hace referencia a los asesinatos del jugador top del equipo azul, y kills_top_rojo a los asesinatos del jugador top del equipo rojo. Por tanto, voy a hacer una descripción de las variables vistas, pero es importante especificar que cuando la variable tiene un \$(color) es porque la variable existe para cada equipo y cuando la variable tiene un \$(posicion) es porque la variable existe para cada jugador de un equipo. La descripción de todas las variables es la siguiente: 

* torneo, el torneo al que pertenece el mapa.
* parte, la parte del torneo al que pertenece el mapa.
* fecha, el día en el que se jugó el mapa.
* semana, la semana o etapa de la parte del torneo en la que se juega el mapa.
* tiempo, la duración en minutos y segundos de la partida.
* parche, versión del juego en el que se jugó la partida.
* nombre_azul, nombre del equipo del lado azul.
* nombre_rojo, nombre del equipo del lado rojo.
* gana_azul, indica con un 1 si gana el equipo azul.
* gana_rojo, indica con un 1 si gana el equipo rojo.
* num_asesinatos_\$(color), el número de asesinatos que ha conseguido un equipo en la partida.
* primera_sangre, nombre del equipo que ha conseguido la primera sangre.
* num_torres_\$(color), número de torres destruidas por el equipo.
* primera_torre, equipo que ha conseguido destruir la primera torre.
* num_dragones_\$(color), número de dragones asesinados por equipo.
* num_dragones_viento_\$(color), número de dragones de viento asesinados por equipo.
* num_dragones_infierno_\$(color), número de dragones de infierno asesinados por equipo.
* num_dragones_oceano_\$(color), número de dragones de océano asesinados por equipo.
* num_dragones_montaña_\$(color), número de dragones de montaña asesinados por equipo.
* num_nashors_\$(color), número de nashors asesinados por equipo.
* num_oro_\$(color), cantidad de oro conseguida por el equipo a final de partida.
* ban_1_\$(color), primer campeón baneado de un equipo.
* ban_2_\$(color), segundo campeón baneado de un equipo.
* ban_3_\$(color), tercer campeón baneado de un equipo.
* ban_4_\$(color), cuarto campeón baneado de un equipo.
* ban_5_\$(color), quinto campeón baneado de un equipo.
* pick_1_\$(color), primer campeón seleccionado de un equipo. El del top.
* pick_2_\$(color), segundo campeón seleccionado de un equipo. El del jungla.
* pick_3_\$(color), tercer campeón seleccionado de un equipo. El del medio.
* pick_4_\$(color), cuarto campeón seleccionado de un equipo. El del adc.
* pick_5_\$(color), quinto campeón seleccionado de un equipo. El del sup.
* top_\$(color), el jugador de un equipo que juega en top.
* jng_\$(color), el jugador de un equipo que juega en jungla.
* mid_\$(color), el jugador de un equipo que juega en mid.
* adc_\$(color), el jugador de un equipo que juega en adc.
* sup_\$(color), el jugador de un equipo que juega en sup.
* kills_\$(posición)_\$(color), el número de asesinatos que ha obtenido un jugador de un equipo.
* assists_\$(posición)_\$(color), el número de asistencias que ha obtenido un jugador de un equipo.
* deaths_\$(posición)_\$(color), el número de muertes que ha obtenido un jugador de un equipo.
* summoner_1_\$(posición)_\$(color), el primer hechizo de invocador que tiene un jugador de un equipo.
* summoner_2_\$(posición)_\$(color), el segundo hechizo de invocador que tiene un jugador de un equipo.
* css_\$(posicion)_\$(color), el número de súbditos asesinados por un jugador de un equipo.
* wards_destroyed_\$(color), el número de guardianes de visión eliminados por equipo.
* wards_placed_\$(color), el número de guardianes de visión colocados por equipo.
* jng_share_15_\$(color), el porcentaje de jungla asesinada por equipo en el minuto 15.
* jng_share_\$(color), el porcentaje de jungla asesinada por equipo al final de partida.
* diferencia_oro_\$(color), la diferencia de oro respecto al otro equipo cada 5 minutos de partida. Extraído a partir de la interacción con una gráfica de puntos.
* oro_\$(color), el oro que tiene un equipo cada 5 minutos de partida. Extraído a partir de la interacción con una gráfica de puntos.
* gold_\$(posicion)_\$(color), el oro que tiene un jugador de un equipo cada 5 minutos de partida. Extraído a partir de la interacción con una gráfica de puntos.
* heraldos_\$(color), el número de heraldos que consiguió asesinar cada equipo.
* inhibs_\$(color), el número de inhibidores que destruyo cada equipo.
* First_Blood, indica que jugador de que equipo consiguió la primera sangre.
* Total_Damage_Dealt_\$(color)_\$(posicion), el daño total realizado por cada jugador de cada equipo.
* Physical_Damage_Dealt_\$(color)_\$(posicion), el daño físico realizado por cada jugador de cada equipo.
* Magic_Damage_Dealt_\$(color)_\$(posicion), el daño físico realizado por cada jugador de cada equipo.
* True_Damage_Dealt_\$(color)_\$(posicion), el daño verdadero realizado por cada jugador de cada equipo.
* Total_Damage_Objectives_\$(color)_\$(posicion), el daño verdadero realizado a objetivos por cada jugador de cada equipo.
* Damage_Taken_\$(color)_\$(posicion), el daño recibido por cada jugador de cada equipo.
* Physical_Damage_Taken_\$(color)_\$(posicion), el daño físico recibido por cada jugador de cada equipo.
* Magic_Damage_Taken_\$(color)_\$(posicion), el daño mágico recibido por cada jugador de cada equipo.
* True_Damage_Taken_\$(color)_\$(posicion), el daño verdadero recibido por cada jugador de cada equipo.
* cs_in_jung_team_\$(color)_\$(posicion), el número de monstruos de la jungla de su equipo asesinados por cada jugador de cada equipo.
* cs_in_jung_enemy_\$(color)_\$(posicion), el número de monstruos de la jungla del equipo enemigo asesinados por cada jugador de cada equipo.
* CSM_\$(color)_\$(posicion), el número de súbditos por minuto asesinados por cada jugador de cada equipo.
* Golds_\$(color)_\$(posicion), el oro final por cada jugador de cada equipo.
* GPM_\$(color)_\$(posicion), el número de súbditos por minuto asesinados por cada jugador de cada equipo.
* GOLD_\$(color)_\$(posicion), el porcentaje de oro total por cada jugador de cada equipo respecto al oro de su equipo.
* Vision_Score_\$(color)_\$(posicion), la puntuación de visión de cada jugador de cada equipo.
* Wards_placed_\$(color)_\$(posicion), el número de guardianes de visión puestos por cada jugador de cada equipo.
* Wards_destroyed_\$(color)_\$(posicion), el número de guardianes de visión destruidos por cada jugador de cada equipo.
* Control_Wards_\$(color)_\$(posicion), el número de guardianes de control de visión puestos por cada jugador de cada equipo.
* VS%_\$(color)_\$(posicion), el porcentaje de puntuación de visión total por cada jugador de cada equipo respecto a la puntuación de visión de su equipo.
* Total_damage_Champios_\$(color)_\$(posicion), el total de daño realizado a enemigos por cada jugador de cada equipo.
* Physical_damage_Champios_\$(color)_\$(posicion), el total de daño físico realizado a enemigos por cada jugador de cada equipo.
* Magic_damage_Champios_\$(color)_\$(posicion), el total de daño mágico realizado a enemigos por cada jugador de cada equipo.
* True_damage_Champios_\$(color)_\$(posicion), el total de daño verdadero realizado a enemigos por cada jugador de cada equipo.
* DPM_\$(color)_\$(posicion), el daño por minuto por cada jugador de cada equipo.
* DMG_\$(color)_\$(posicion), el porcentaje de daño total por cada jugador de cada equipo respecto al daño total de su equipo.
* Solo_kills_\$(color)_\$(posicion), el número de asesinatos en solitario realizados por cada jugador de cada equipo.
* Double_kills_\$(color)_\$(posicion), el número de asesinatos dobles realizados por cada jugador de cada equipo.
* Triple_kills_\$(color)_\$(posicion), el número de asesinatos triples realizados por cada jugador de cada equipo.
* Quadra_kills_\$(color)_\$(posicion), el número de asesinatos cuádruples realizados por cada jugador de cada equipo.
* Penta_kills_\$(color)_\$(posicion), el número de asesinatos quíntuples realizados por cada jugador de cada equipo.
* CSD@15_\$(color)_\$(posicion), la diferencia en súbditos asesinados respecto a su enemigo en su posición por cada jugador de cada equipo.
* XPD@15_\$(color)_\$(posicion), la diferencia en experiencia respecto a su enemigo en su posición por cada jugador de cada equipo.
* LVLD@15_\$(color)_\$(posicion), la diferencia en niveles respecto a su enemigo en su posición por cada jugador de cada equipo.
* Damage_towers_\$(color)_\$(posicion), el daño a torres realizado por cada jugador en cada partida.
* heal_\$(color)_\$(posicion), la cantidad de curación realizada por cada jugador en cada partida.
* ccing\$(color)_\$(posicion), el tiempo de paralizaciones, ralentizaciones, etc realizado por cada jugador en cada partida.

# 2. Selección de los datos. 

Como tenemos muchas variables, tenemos que eliminar aquellas que no vayamos a usar o que no sean muy importantes o supongan información que se recoge en otras variables. 

Es importante recordar que el objetivo del estudio y de los análisis estadísticos que realizaremos posteriormente es estudiar factores relacionados con la victoria de un equipo, identificar su influencia y el equipo a ganar. **Por tanto, voy a seleccionar los datos y eliminar variables en función de su esperada utilidad para identificar el ganador y de la relación con otras variables en el dataset, evitando tener variables que pueden ser del mismo ámbito o tener influencias parecidas en el ganador de la partida.**

## Variables no necesarias.

De primeras, podemos eliminar la fecha, parche, nombre de equipos, nombre de jugadores o campeones o los summoners utilizados. Aunque estos aspectos son importantes para ganar, como por ejemplo jugar un campeón agresivo o defensivo, los eliminamos del conjunto de datos puesto que son factores difíciles de analizar en un análisis estadístico debido a la cantidad de factores que tienen. 

Antes de eliminar el equipo hay que cambiar el valor de las variables primera_sangre y primera_torre, para identificar si la obtuvo el equipo rojo o el azul.


```{r,eval=TRUE,echo=TRUE}

# codifico los factores correctamente
lol$primera_sangre <- as.factor(ifelse(as.character(lol$primera_sangre) == as.character(lol$nombre_azul), 'azul','rojo'))
lol$primera_torre <- as.factor(ifelse(as.character(lol$primera_torre) == as.character(lol$nombre_azul), 'azul','rojo'))

# variables que voy a eliminar
eliminar <- c('torneo','parte', 'fecha','semana', 'parche','nombre_rojo','nombre_azul', 'top_azul', 'jng_azul','mid_azul','adc_azul','sup_azul','top_rojo', 'jng_rojo','mid_rojo','adc_rojo','sup_rojo')

# elimino variables
lol<-lol %>% select(-(all_of(eliminar))) 
lol<-lol %>% select(-(contains("ban")| contains("pick")| contains("summoner")))

# demuestro el cambio en las variables
head(lol) %>% select(c("primera_sangre", "primera_torre"))
```

## Variables duplicadas 

Además, en el dataset hay información duplicada respecto a algunas variables, como por ejemplo el oro o los subditos asesinados. Es importante mencionar que siempre que se puede, se intenta trabajar con el valor de la variable por minuto, puesto que no sirve de nada si un equipo consigue mucho oro pero simplemente es porque pierde la partida y esta partida es muy larga. 

A continuación voy seleccionando los datos que me interesan del dataset respecto a diferentes aspectos de la partida, para reducir el dataset y obtener los mismos datos solo de una manera.

### Creeps (Subditos)

Para los subditos, **tenemos la variable CSM_posición_equipo que queremos mantener, ya que representa los subditos por minuto, el resto de variables respecto a los subditos se eliminan.** Por una parte css_posicion_equipo es la misma información sin tener encuenta el tiempo. Por otra parte, las variables cs_in_jung_team y cs_in_jung_enemy, son variables muy específicas, que actualmente no vamos a usar en los análisis y que se encuentran ya sus valores dentro de la variable CSM_posicion_equipo. 
Respecto a las variables de CSD.15_equipo_posicion, que representan la diferencia de cs al minuto 15 para cada posición de los equipos, no la selecciono, porque la diferencia de cs en media partida, aunque es importante, está incluida en los CS por minuto. 

```{r,eval=TRUE,echo=TRUE}

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("css_")| contains("cs_in_jung")| contains("CSD.15")))
head(lol) %>% select(contains("CSM"))
```

### Asesinatos, Muertes y Asistencias. 

**La información de asesinatos, muertes y asistencias se puede condensar en una métrica que se suele utilizar en el juego, que es el KDA,** este KDA se compone por (Asesinatos+Asistencias)/Muertes, de tal manera que generamos un KDA para cada jugador de la partida, condensando la información de Kills, Deaths y Assists de cada jugador en una variable. 

Por otra parte, aunque el desempeño de un jugador es muy importante de estudiar para ver si el equipo gana o pierde, ya que puede ser que solo un jugador haga que un equipo gane, en estos análisis nos vamos a centrar más en estudios respecto al desempeño del equipo, mirando solo en pocas variables clave el desempeño de los jugadores. Es por esto, que mientras que conservamos los KDA para cada jugador, **la información de solokills, doblekills, triplekills, cuadrakills y pentakills, las vamos a agrupar en una por equipo.**

```{r,eval=TRUE,echo=TRUE}

# genero las variables de kda
lol$kda_top_azul <- (lol$kills_top_azul+lol$assists_top_azul)/lol$deaths_top_azul
lol$kda_jng_azul <- (lol$kills_jng_azul+lol$assists_jng_azul)/lol$deaths_jng_azul
lol$kda_mid_azul <- (lol$kills_mid_azul+lol$assists_mid_azul)/lol$deaths_mid_azul
lol$kda_adc_azul <- (lol$kills_adc_azul+lol$assists_adc_azul)/lol$deaths_adc_azul
lol$kda_sup_azul <- (lol$kills_sup_azul+lol$assists_sup_azul)/lol$deaths_sup_azul

lol$kda_top_rojo <- (lol$kills_top_rojo+lol$assists_top_rojo)/lol$deaths_top_rojo
lol$kda_jng_rojo <- (lol$kills_jng_rojo+lol$assists_jng_rojo)/lol$deaths_jng_rojo
lol$kda_mid_rojo <- (lol$kills_mid_rojo+lol$assists_mid_rojo)/lol$deaths_mid_rojo
lol$kda_adc_rojo <- (lol$kills_adc_rojo+lol$assists_adc_rojo)/lol$deaths_adc_rojo
lol$kda_sup_rojo <- (lol$kills_sup_rojo+lol$assists_sup_rojo)/lol$deaths_sup_rojo

# genero variables asesinatos
lol$solo_k_azul <- lol %>% select(contains("Solo_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$double_k_azul <- lol %>% select(contains("Double_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$triple_k_azul <- lol %>% select(contains("Triple_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$quadra_k_azul <- lol %>% select(contains("Quadra_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$penta_k_azul <- lol %>% select(contains("Penta_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$solo_k_rojo <- lol %>% select(contains("Solo_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$double_k_rojo <- lol %>% select(contains("Double_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$triple_k_rojo <- lol %>% select(contains("Triple_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$quadra_k_rojo <- lol %>% select(contains("Quadra_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$penta_k_rojo <- lol %>% select(contains("Penta_kills_rojo"))%>% rowSums(na.rm = TRUE)

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("kills")| contains("deaths")| contains("assists")))
head(lol) %>% select(contains("kda")| contains("_k_"))

```

### Oro.

El oro es la estadística más importante del juego. Los asesinatos, los subditos, las torres, los monstruos de la jungla, todos los objetivos del juego cuando se consiguen te otorgan oro, por tanto, está claro que un equipo que gana en la gran mayoría de partidas, tiene más oro que el equipo perdedor. 
**A continuación, demuestro esto para eliminar la variable que se refiere al oro final del dataset.**

```{r,eval=TRUE,echo=TRUE}

# genero la variable gana
lol$gana <- as.factor(ifelse(lol$gana_azul == 1, 'azul','rojo'))

# transformo las variables de oro a número
require(stringr)
lol$num_oro_azul <- as.integer(str_replace(lol$num_oro_azul,'k',''))*1000
lol$num_oro_rojo <- as.integer(str_replace(lol$num_oro_rojo,'k',''))*1000

# genero la variable mas oro en función de que equipo acabo con más oro
lol$mas_oro <- as.factor(ifelse(lol$num_oro_azul == lol$num_oro_rojo, 'iguales', ifelse(lol$num_oro_azul > lol$num_oro_rojo, 'mas_azul','mas_rojo') ))

# muestro la tabla de quien gana en función del oro
table(lol$mas_oro,lol$gana)

# elimino las variables de oro final
eliminar2 <- c('num_oro_azul','num_oro_rojo', 'mas_oro','gana_azul', 'gana_rojo')
lol<-lol %>% select(-(all_of(eliminar2))) 

```

Se observa perfectamente que es cierto, y que posiblemente los pocos casos donde el equipo con menos oro gana, es una partida muy igualada. Por tanto, como hacer una correlación o un modelo de regresión con la variable de oro al final de la partida sería un poco trampa, puesto que ya sabemos que hay una gran correlación entre el oro y ganar la partida, la metodología típica para analizar el oro de los equipos se suele medir por el oro en el minuto 15 de los equipos. En este minuto, las partidas no están decididas, pero si podemos ver si hay un equipo que ha dominado claramente los primeros minutos de la partida. **Por tanto, vamos a trabajar con el oro del equipo en el minuto 15, y con la diferencia de oro en estos minutos.**

El oro de cada jugador no lo vamos a usar, porque aunque sea muy util, realmente este oro se consigue con los objetivos que ya se ven representados en el dataset, asique no hace falta tener información de oro por cada jugador. Por tanto eliminamos todas las variables ya sean temporales o de final de partida, que hacen referencia al oro.
**Eso sí, vamos a usar la variable GPM_equipo_posicion para detectar cual fue el jugador con más oro por equipo y nos quedamos con esta posición como jugador más valioso del equipo. Generado una nueva variable. **


```{r,eval=TRUE,echo=TRUE}

# reformateo la variable de oro azul y rojo para generar el oro al 15
oro_azul<-str_split(lol$oro_azul, ',')
lol$oro_al_15_azul<-unlist(lapply(oro_azul, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

oro_rojo<-str_split(lol$oro_rojo, ',')
lol$oro_al_15_rojo<-unlist(lapply(oro_rojo, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

# la diferencia será positiva si es para el azul o negativa para el rojo
diferencia_oro<-str_split(lol$diferencia_oro_azul, ',')
lol$diff_oro_al_15<-unlist(lapply(diferencia_oro, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

# genero las variables de masvalioso para cada equipo
lol<-lol %>% mutate(MasValioso_azul = case_when(
    (GPM_azul_top >= GPM_azul_jng) & (GPM_azul_top >= GPM_azul_mid) & (GPM_azul_top >= GPM_azul_adc) & (GPM_azul_top >= GPM_azul_sup) ~ "top",
    (GPM_azul_jng >= GPM_azul_top) & (GPM_azul_jng >= GPM_azul_mid) & (GPM_azul_jng >= GPM_azul_adc) & (GPM_azul_jng >= GPM_azul_sup) ~ "jng",
    (GPM_azul_mid >= GPM_azul_top) & (GPM_azul_mid >= GPM_azul_jng) & (GPM_azul_mid >= GPM_azul_adc) & (GPM_azul_mid >= GPM_azul_sup) ~ "mid",
    (GPM_azul_adc >= GPM_azul_top) & (GPM_azul_adc >= GPM_azul_jng) & (GPM_azul_adc >= GPM_azul_mid) & (GPM_azul_adc >= GPM_azul_sup) ~ "adc",
    TRUE ~ 'sup'
  )
)
lol<-lol %>% mutate(MasValioso_rojo = case_when(
    (GPM_rojo_top >= GPM_rojo_jng) & (GPM_rojo_top >= GPM_rojo_mid) & (GPM_rojo_top >= GPM_rojo_adc) & (GPM_rojo_top >= GPM_rojo_sup) ~ "top",
    (GPM_rojo_jng >= GPM_rojo_top) & (GPM_rojo_jng >= GPM_rojo_mid) & (GPM_rojo_jng >= GPM_rojo_adc) & (GPM_rojo_jng >= GPM_rojo_sup) ~ "jng",
    (GPM_rojo_mid >= GPM_rojo_top) & (GPM_rojo_mid >= GPM_rojo_jng) & (GPM_rojo_mid >= GPM_rojo_adc) & (GPM_rojo_mid >= GPM_rojo_sup) ~ "mid",
    (GPM_rojo_adc >= GPM_rojo_top) & (GPM_rojo_adc >= GPM_rojo_jng) & (GPM_rojo_adc >= GPM_rojo_mid) & (GPM_rojo_adc >= GPM_rojo_sup) ~ "adc",
    TRUE ~ 'sup'
  )
)
  

# elimino variables y demuestro los cambios
eliminar3 <- c('oro_azul','oro_rojo', 'diferencia_oro_azul','diferencia_oro_rojo')

lol<-lol %>% select(-(all_of(eliminar3)))
lol<-lol %>% select(-(contains("Golds")| contains("GPM")| contains("gold")))
head(lol) %>% select(c("oro_al_15_azul", "oro_al_15_rojo", "diff_oro_al_15", "MasValioso_azul", "MasValioso_rojo"))

```

### Vision

En el juego se consigue visión el mapa gracias a la visión, está claro que cuanto más tiempo pasa, más wards se colocan en el mapa y se destruyen, por tanto las variables tienen que estar estandarizadas por el tiempo de la partida. 

Debido a que se pueden poner wards normales o de control de visión, además que es importante no solo poner los wards sino eliminarlos, se creó la métrica Vision Score o VS. Esta métrica representa una puntuación que recoje wards colocados, eliminados y la calidad de la visión que otorgan los wards. **Por tanto, en el estudio vamos a usar solo la puntuación de Vision Score, eliminando el resto de variables. Además, aunque puede ser útil saber el desempeño de cada jugador en la visión del equipo, debido a que no vamos a realizar grandes análisis sobre la visión en el trabajo, agrupamos la vision score por equipos, generando una vision score para el equipo azul y otra para el rojo.**

```{r,eval=TRUE,echo=TRUE}

# me quedo solo con los minutos en la fecha
fecha <- str_split(lol$tiempo,':')
lol$tiempo<-unlist(lapply(fecha, function(x) as.integer(unlist(x)[1])))

# genero el scorevision por minuto
lol<-lol %>% mutate(ScoreVision_azul = (Vision_Score_azul_top + Vision_Score_azul_jng + Vision_Score_azul_mid + Vision_Score_azul_adc + Vision_Score_azul_sup)/tiempo)
lol<-lol %>% mutate(ScoreVision_rojo = (Vision_Score_rojo_top + Vision_Score_rojo_jng + Vision_Score_rojo_mid + Vision_Score_rojo_adc + Vision_Score_rojo_sup)/tiempo)

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("Wards")| contains("Vision_Score")| contains("VS")))
head(lol) %>% select(contains("ScoreVision"))




```

### Daño

Respecto al daño tenemos muchas variables. Tenemos información sobre el daño total realizado y de que tipo de daño es, el daño recibido, el daño realizado a objetivos, el daño a campeones enemigos, el daño por minuto a enemigos, el porcentaje de daño por persona en cada equipo, el daño a torres, etc. 

De nuevo, aunque es importante el daño por cada jugador, es obvio que eso son muchas variables y por tanto, **la única variable que vamos a mantener por jugador es la de daño por minuto (DPM). Como este daño es daño a campeones, podemos eliminar las variables que hacen referencia a daño a campeones total y porcentaje de daño. La información de daño mágico, físico o verdadero a campeones que tenemos por jugador, la condensamos en equipo y la dividimos por minuto, para saber la cantidad de cada tipo a campeones.**
**Además, el daño realizado a objetivos se combina por equipos y se divide por minuto.** Respecto al daño total y daño recibido,se eliminan las variables porque el daño total no es tan importante, sino que nos centramos en el daño en campeones y objetivos y porque el daño recibido por un equipo es inverso al daño realizado por el otro y si ya tenemos los daños realizados por equipo no tiene sentido tener el recibido. 

Por último, el daño a torres se recoge obviamente en el número de torres eliminadas, por tanto se puede eliminar la variable. 

```{r,eval=TRUE,echo=TRUE}



# genero las variables que agrupan el daño por equipo por minuto
lol<-lol %>% mutate(PhysicalDamageChampions_azul = (Physical_Damage_Champions_azul_top + Physical_Damage_Champions_azul_jng + Physical_Damage_Champions_azul_mid + Physical_Damage_Champions_azul_adc + Physical_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(PhysicalDamageChampions_rojo = (Physical_Damage_Champions_rojo_top + Physical_Damage_Champions_rojo_jng + Physical_Damage_Champions_rojo_mid + Physical_Damage_Champions_rojo_adc + Physical_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(MagicDamageChampions_azul = (Magic_Damage_Champions_azul_top + Magic_Damage_Champions_azul_jng + Magic_Damage_Champions_azul_mid + Magic_Damage_Champions_azul_adc + Magic_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(MagicDamageChampions_rojo = (Magic_Damage_Champions_rojo_top + Magic_Damage_Champions_rojo_jng + Magic_Damage_Champions_rojo_mid + Magic_Damage_Champions_rojo_adc + Magic_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(TrueDamageChampions_azul = (True_Damage_Champions_azul_top + True_Damage_Champions_azul_jng + True_Damage_Champions_azul_mid + True_Damage_Champions_azul_adc + True_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(TrueDamageChampions_rojo = (True_Damage_Champions_rojo_top + True_Damage_Champions_rojo_jng + True_Damage_Champions_rojo_mid + True_Damage_Champions_rojo_adc + True_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(DamageObjectives_azul = (Total_Damage_Objectives_azul_top + Total_Damage_Objectives_azul_jng + Total_Damage_Objectives_azul_mid + Total_Damage_Objectives_azul_adc + Total_Damage_Objectives_azul_sup)/tiempo)
lol<-lol %>% mutate(DamageObjectives_rojo = (Total_Damage_Objectives_rojo_top + Total_Damage_Objectives_rojo_jng + Total_Damage_Objectives_rojo_mid + Total_Damage_Objectives_rojo_adc + Total_Damage_Objectives_rojo_sup)/tiempo)

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("Damage_Dealt")| contains("Damage_Objectives")| contains("Damage_Taken")| contains("Damage_Champions")| contains("DMG")| contains("Damage_towers")| contains("damage_Champios")))
head(lol) %>% select(contains("DPM") | contains( "Damage"))



```

### Experiencia y niveles

Para la información de experiencia y niveles en el juego, ocurre como con el oro, que evidentemente cuando un equipo gana la partida, tiene más nivel y experiencia que el contrario. **Por tanto, se trabaja con las variables al minuto 15. Concretamente tenemos la diferencia de experiencia y niveles.** Mantenemos ambas variables porque mientras que tener un nivel de ventaja puede suponer mucho en el minuto 15, realmente no sabemos si esto es porque se tiene una pequeña ventaja y justo al 15 había un jugador superior al otro, o porque la diferencia entre jugadores es muy grande realmente. 
Como trabajamos con diferencia de experiencia entre cada jugador de cada posición para los equipos, tendremos solo una variable, que será positiva si la ventaja la tiene el equipo azul y negativa si la tiene el rojo. 

```{r,eval=TRUE,echo=TRUE}

# genero las variables de diferencia de exp y nivel en el minuto 15
lol<-lol %>% mutate(diferencia_exp = XPD.15_azul_top + XPD.15_azul_jng + XPD.15_azul_mid + XPD.15_azul_adc + XPD.15_azul_sup)
lol<-lol %>% mutate(diferencia_nivel = LVLD.15_azul_top + LVLD.15_azul_jng + LVLD.15_azul_mid + LVLD.15_azul_adc + LVLD.15_azul_sup)

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("XPD.15")| contains("LVLD.15")))
head(lol) %>% select(contains("exp")| contains( "nivel"))


```

### Curaciones y control de campeones.

Las curaciones se pueden realizar en el juego por diversas maneras, ya sean robo de vida, campeones que curan o con pociones. **Por tanto se mantiene la variable pero se agrupa y convierte a curación por minuto.**
El control de campeones es vital en muchas partidas, consiste en el tiempo que un campeon enemigo es inmovilizado o ralentizado por un campeon. **Igual que las curaciones, agrupamos por equipo y se convierte a cc por minuto.**

```{r,eval=TRUE,echo=TRUE}

# genero las variables de curacion y cc
lol<-lol %>% mutate(cura_azul = (heal_azul_top + heal_azul_jng + heal_azul_mid + heal_azul_adc + heal_azul_sup)/tiempo)
lol<-lol %>% mutate(cura_rojo = (heal_rojo_top + heal_rojo_jng + heal_rojo_mid + heal_rojo_adc + heal_rojo_sup)/tiempo)
lol<-lol %>% mutate(cc_azul = (ccing_azul_top + ccing_azul_jng + ccing_azul_mid + ccing_azul_adc + ccing_azul_sup)/tiempo)
lol<-lol %>% mutate(cc_rojo = (ccing_rojo_top + ccing_rojo_jng + ccing_rojo_mid + ccing_rojo_adc + ccing_rojo_sup)/tiempo)

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("ccing")| contains("heal")))
head(lol) %>% select(contains("cura") | contains( "cc"))


```


### Porcentaje de jungla.

Las variables jng_share_15 y jng_share, representan el porcentaje de monstruos de la jungla que ha tenido un equipo respecto al otro. **Evidentemente, ambas variables son complementarias para cada equipo, por lo que podemos quedarnos solo con una, que será el extra de porcentaje de jungla que ha tenido el equipo azul respecto al rojo.** Si el valor es positivo es que el azul ha matado más monstruos de la jungla y si es negativo es el rojo el equipo que ha matado más monstruos de la jungla. 

```{r,eval=TRUE,echo=TRUE}

# genero las variables de ventaja en jungla
lol<-lol %>% mutate(ventaja_jung_15 = as.numeric(as.character(jng_share_15_azul)) - as.numeric(as.character(jng_share_15_rojo)))
lol<-lol %>% mutate(ventaja_jung = as.numeric(as.character(jng_share_azul)) - as.numeric(as.character(jng_share_rojo)))

# elimino variables y demuestro los cambios
lol<-lol %>% select(-(contains("share")))
head(lol) %>% select(contains("ventaja"))


```



# 3. Limpieza de los datos

Hasta ahora hemos seleccionado una gran cantidad de los datos del dataset, centrándonos en quedarnos con las variables que más útiles pueden ser en relación al ganador de la partida. Tan importante es tener los datos importantes, como que estos estén limpios y correctos para los análisis de datos. Si los datos a analizar están con valores no válidos, el conocimiento extraído no será útil. Lo que se conoce como "garbage in, garbage out".

Por tanto, hemos de limpiar los datos. Principalmente me centro en eliminar los elementos vacíos y en eliminar los valores extremos. 

Como primer paso de la limpieza de los datos, tenemos que mirar el tipo de los diferentes atributos del dataset.
```{r,eval=TRUE,echo=TRUE}

sapply(lol, class) 

```

Vemos que todas las variables tienen el tipo correcto salvo las de subditos por minuto (CSM). Por tanto, hemos de corregir su tipo a numeric. 
También falla el tipo de las variables MasValiosoAzul y MasValiosoRojo, que aparecen como character y tienen que ser factores. 

```{r,eval=TRUE,echo=TRUE}

# cambio el tipo de las variables de CSM a número
lol$CSM_azul_top <- as.numeric(as.character(lol$CSM_azul_top))
lol$CSM_azul_jng <- as.numeric(as.character(lol$CSM_azul_jng))
lol$CSM_azul_mid <- as.numeric(as.character(lol$CSM_azul_mid))
lol$CSM_azul_adc <- as.numeric(as.character(lol$CSM_azul_adc))
lol$CSM_azul_sup <- as.numeric(as.character(lol$CSM_azul_sup))
lol$CSM_rojo_top <- as.numeric(as.character(lol$CSM_rojo_top))
lol$CSM_rojo_jng <- as.numeric(as.character(lol$CSM_rojo_jng))
lol$CSM_rojo_mid <- as.numeric(as.character(lol$CSM_rojo_mid))
lol$CSM_rojo_adc <- as.numeric(as.character(lol$CSM_rojo_adc))
lol$CSM_rojo_sup <- as.numeric(as.character(lol$CSM_rojo_sup))

# cambio el tipo de las variables de mas valioso a factor
lol$MasValioso_azul<- as.factor(lol$MasValioso_azul)
lol$MasValioso_rojo<- as.factor(lol$MasValioso_rojo)


```

A continuación muestro las dimensiones del dataset y el str, sin limpiar.

```{r,eval=TRUE,echo=TRUE}

# Comprobar los datos presentes antes de limpiar
str(lol) 

# Comprobar que las dimensiones del dataframe son correctas, 614 filasx88columnas
dim(lol)

```

## 3.1 Datos vacíos. 

Vamos a estudiar si el conjunto de datos presenta elementos vacíos o ceros. En caso de que haya una variable igual a 0, esto puede ser porque el valor es realmente 0 o porque es un elemento perdido, igual que los elementos vacíos. Estos elementos vacíos por tanto, pueden aparacer como 0, NA o como un valor indicativo de que falta el valor como '-'. 

En caso de que un valor sea 0 tenemos que identificar su causa. Para todos aquellos elementos vacíos tendremos que decidir como solucionar la falta de información. Por una parte, se puede eliminar la instancia, suponiendo una perdida de datos. Otra solución es dejar claro que falta ese dato con una etiqueta como por ejemplo 'Desconocido', esta solución puede ser efectiva sobre todo para las variables que son un factor. Una solución algo más interesante es sustituir el valor por una medida de tendencia central como la media o mediana en las variables numéricas, o la clase más utilizada en las variables categóricas. Por último, se pueden imputar estos valores vacíos en función de los valores del conjunto de datos mediante métodos probabilistas. Esta última solución suele ser la mejor porque el valor no es el mismo para todas las instancias que se encuentran vacías. 

**Compruebo si los datos tienen elementos iguales a 0 o elementos vacíos:**



```{r,eval=TRUE,echo=TRUE}

# Compruebo los elementos que son 0
sapply(lol, function(x) sum(x==0, na.rm=T))

```


Vemos que hay muchas variables con 0, pero tenemos que tener en cuenta que en todas estas variables es algo normal. Es muy posible que los asesinatos de un equipo o otro sean 0, lo mismo puede ocurrir con torres, dragones, nashors, heraldos, inhibidores, rachas de asesinatos o asesinatos en solitario. Todo esto ocurre porque un equipo puede ir muy mal y no conseguir asesinatos o objetivos, lo cual hace que su valor sea 0. 
Otras variables con 0 son la diferencia de nivel, y la ventaja en la jungla, las cuáles es posible también que sean 0 porque no haya diferencias entre ambos equipos. 
Las últimas variables a comentar que es lógico que tengan 0 son los kda de los jugadores, de nuevo, esto se explica porque un jugador ha muerto varias veces y no ha asesinado ni ayudado en nada. Se da en pocas ocasiones, pero en partidas a gran nivel es posible, ya que muchas veces un equipo es capaz de dominar toda la partida sin dar opciones al rival. 
Por último, se observa un 0 en CSM_rojo_sup, esto se puede deber a que un jugador no asesinó ningún súbdito en la partida, aunque extraño, es posible y sobretodo en los support, se puede estar jugando algún support muy defensivo (como puede ser una soraka o yuumi) que no haya asesinado ningún súbdito.

Para estudiar porque puede ocurrir el valor de 0 en CSM_rojo_sup, accedemos al dataset lol_base y busco el campeón jugado para ver si es cierta mi suposición. 

```{r,eval=TRUE,echo=TRUE}

as.character(lol_base[which(lol_base$CSM_rojo_sup=='0'),]$pick5_rojo)
```

Efectivamente, vemos que el campeón que consiguió 0 de CSM era Yuumi, este campeón se caracteriza por que se sube a un compañero suyo y no ataca, sino que se dedica a protegerle, por lo que es bastante aceptable que tuviera 0 subditos en la partida. 

Por tanto, mantenemos todos los 0 en el conjunto de datos, puesto que todos parecen ser valores lógicos y correctos. 

**A continuación estudio los valores vacíos del dataset.**

```{r,eval=TRUE,echo=TRUE}

sapply(lol, function(x) sum(is.na(x) | x==''))

```

Vemos que hay varias variables con valores vacíos. Para todas estas variables podemos considerar que se debe a errores en el web scraping o que faltaba la información en la propia web. Por tanto, habrá que solucionar estos valores vacíos para las variables que hacen referencia a heraldos, inhibidores, oro al 15, puntuación de visión, daño a objetivos, diferencia de nivel o experiencia, valores de curación o de cc, o FirstBlood. 

Eso sí quiero estudiar porque se produce el NA en las variables de kda de los jugadores, puesto que es un campo calculado en este estudio y es posible que haya un problema en el cálculo. Para esto miro en lol_base, los asesinatos, muertes y asistencias de aquellos jugadores que tienen NA en su kda. Para simplificarlo todo, solo miro los de kda_adc_rojo que es el que más NA tiene. 


```{r,eval=TRUE,echo=TRUE}

# del dataset base, selecciono asesinatos, muertes y asistencias de los que tienen en na en el kda_adc_rojo
lol_base[which(is.na(lol$kda_adc_rojo)),]$kills_adc_rojo
lol_base[which(is.na(lol$kda_adc_rojo)),]$deaths_adc_rojo
lol_base[which(is.na(lol$kda_adc_rojo)),]$assists_adc_rojo
```

Vemos que estos jugadores, no asesinaron, ni asistieron, ni fueron asesinados en la partida, por lo que el cálculo de su KDA es 0+0/0 que es NA, por tanto, realmente este valor de las variables KDA que es NA, tiene que ser sustituido por el valor 0. 

**Para el resto de variables tenemos que imputar los NA. Lo realizo mediante el método de kNN.** Este método se basa en la similitud entre diferentes atributos del dataset, de manera que se puede estimar el valor de un atributo vacío en funcion de los atributos más parecidos a este. 

```{r,eval=TRUE,echo=TRUE}


# corrijo los valores de kdas
lol$kda_top_azul <- ifelse(is.na(lol$kda_top_azul), 0, lol$kda_top_azul)
lol$kda_jng_azul <- ifelse(is.na(lol$kda_jng_azul), 0, lol$kda_jng_azul)
lol$kda_mid_azul <- ifelse(is.na(lol$kda_mid_azul), 0, lol$kda_mid_azul)
lol$kda_adc_azul <- ifelse(is.na(lol$kda_adc_azul), 0, lol$kda_adc_azul)
lol$kda_sup_azul <- ifelse(is.na(lol$kda_sup_azul), 0, lol$kda_sup_azul)

lol$kda_top_rojo <- ifelse(is.na(lol$kda_top_rojo), 0, lol$kda_top_rojo)
lol$kda_jng_rojo <- ifelse(is.na(lol$kda_jng_rojo), 0, lol$kda_jng_rojo)
lol$kda_mid_rojo <- ifelse(is.na(lol$kda_mid_rojo), 0, lol$kda_mid_rojo)
lol$kda_adc_rojo <- ifelse(is.na(lol$kda_adc_rojo), 0, lol$kda_adc_rojo)
lol$kda_sup_rojo <- ifelse(is.na(lol$kda_sup_rojo), 0, lol$kda_sup_rojo)

# asigno NA a las primeras sangres que no están
lol$First_Blood<-ifelse(lol$First_Blood=='',NA, as.character(lol$First_Blood))

# Consigo el nombre de las variables con nulos
nulls<-as.data.frame(sapply(lol, function(x) sum(is.na(x))))
colnames(nulls) <- 'nulls'
nulls$index <-rownames(nulls)
vars_with_nulls<-nulls[which(nulls$nulls!=0),]$index

# imputo los valores
lol_imputed<-kNN(lol, k=3)

# muestro que se han corregido los nulos. 
sapply(lol_imputed[vars_with_nulls], function(x) sum(is.na(x)))

# pongo el tipo de first_blood bien
lol_imputed$First_Blood <- as.factor(as.character(lol_imputed$First_Blood))


```

## 3.2 Valores extremos. 

Los valores extremos son datos que se encuentran tan alejados de los valores normales de una variable que hacen sospechar si estos valores son realmente válidos o si por el contrario se deben a un error en la recolección de los datos. En caso de observar que realmente los errores no son erróneos aunque si extremos, se pueden mantener los valores. Si se detectan que los valores extremos son debido a problemas y erróneos, entonces se tienen que corregir, ya sea mediante una transformación lógica (quizás se tengan que cambiar decimales) o mediante una imputación de los valores como si de valores vacíos se trataran.

Es importante destacar que los valores extremos, obviamente solo se pueden obtener para aquellas variables que son numéricas.

**Primero vamos a estudiar los valores extremos para detectarlos:**

```{r,eval=TRUE,echo=TRUE}

# selecciono las variables numéricas
lol_numericas <- lol_imputed %>% select(where(is.numeric) | where(is.integer))

# estudio sus outliers
sapply(lol_numericas, function(x) boxplot.stats(x)$out)



```

Se observa que hay una gran cantidad de variables que tienen valores extremos, eso sí, vemos que todos los outliers tienen más o menos sentido en las distribuciones de los datos. Es decir, que aunque en el boxplot se detecta un outlier, este es simplemente un candidato a valor extremo, pero al compararlo con los datos en los boxplots, vemos que realmente este valor es un valor real válido, y que aparece como un outlier por simple distribución de los datos. Es normal, que haya alguna partida que un jugador sobresalga y se haga una cantidad de subditos por minuto alta pero POSIBLE, o que un equipo juegue una composición de curar y por tanto su valor de cura sea muy alto pero POSIBLE, o que se detecten 6 inhibidores como un valor extremo porque normalmente un equipo puede ganar uno o dos pero los inhibidores pueden reaparecer a los 5 minutos con lo que el enemigo tienen que volver a destruirlo. 

Para ejemplicar como se ven los outliers de las variables en los boxplots, y entender visualmente porque estos valores son posibles, visualizamos los súbditos por minuto de los jugadores. 

```{r,eval=TRUE,echo=TRUE,, fig.height=3, fig.width=3}


# selecciono las variables de csms
lol_csms <- lol_imputed %>% select(c('CSM_azul_top','CSM_azul_jng','CSM_azul_mid','CSM_azul_adc','CSM_azul_sup','CSM_rojo_top','CSM_rojo_jng','CSM_rojo_mid','CSM_rojo_adc','CSM_rojo_sup'))

# estudio sus boxplot
sapply(lol_csms, function(x) boxplot(x))


```

Para todas las variables de CSM, podemos ver que los outliers que se han identificado no están muy lejos de la distribución de las variables y que son POSIBLES, simplemente se detectan como outliers porque son valores que se encuentran muy extremos en la distribución, pero desde luego se ve que son valores que se pueden obtener sin problemas en la partida ya que se encuentran en un rango lógico. 


**Vemos como se le puede identificar una lógica a la posible aparación de los outliers en los datos para casi todas las variables,** una importante de mencionar es el valor de Infinito para las variables de KDA que se produce cuando un jugador no ha muerto en la partida pero al menos ha conseguido una asistencia o asesinato. Para estas variables podríamos dejar el valor Inf puesto que no está mal, es cierto, pero se puede optar por simplemente volver a los datos iniciales (lol_base) y recalcular el KDA teniendo en cuenta que si las muertes de un jugador son 0, se sustituye el valor por 1. De tal manera que si un jugador asesinó 5 veces, asistió en 2 asesinatos y no murió su KDA será 7 en vez de Infinito. Así podemos distinguir cuando un jugador domina mucho la partida matando mucho y no muere, que podría tener un KDA de 25, y un jugador que no domina pero tampoco muere y podría tener un KDA de 3. Sin hacer esto ambos tendrían Infinito. 

```{r,eval=TRUE,echo=TRUE}

# utilizo lol2 para generar bien los kdas
lol2<-lol_base

lista<-c('deaths_top_azul','deaths_jng_azul','deaths_mid_azul','deaths_adc_azul','deaths_sup_azul','deaths_top_rojo','deaths_jng_rojo','deaths_mid_rojo','deaths_adc_rojo','deaths_sup_rojo')
lol2[lista]<-as.data.frame(sapply(lol2[lista], function(x) ifelse(x==0,1,x)))

lol2$kda_top_azul <- (lol2$kills_top_azul+lol2$assists_top_azul)/lol2$deaths_top_azul
lol2$kda_jng_azul <- (lol2$kills_jng_azul+lol2$assists_jng_azul)/lol2$deaths_jng_azul
lol2$kda_mid_azul <- (lol2$kills_mid_azul+lol2$assists_mid_azul)/lol2$deaths_mid_azul
lol2$kda_adc_azul <- (lol2$kills_adc_azul+lol2$assists_adc_azul)/lol2$deaths_adc_azul
lol2$kda_sup_azul <- (lol2$kills_sup_azul+lol2$assists_sup_azul)/lol2$deaths_sup_azul

lol2$kda_top_rojo <- (lol2$kills_top_rojo+lol2$assists_top_rojo)/lol2$deaths_top_rojo
lol2$kda_jng_rojo <- (lol2$kills_jng_rojo+lol2$assists_jng_rojo)/lol2$deaths_jng_rojo
lol2$kda_mid_rojo <- (lol2$kills_mid_rojo+lol2$assists_mid_rojo)/lol2$deaths_mid_rojo
lol2$kda_adc_rojo <- (lol2$kills_adc_rojo+lol2$assists_adc_rojo)/lol2$deaths_adc_rojo
lol2$kda_sup_rojo <- (lol2$kills_sup_rojo+lol2$assists_sup_rojo)/lol2$deaths_sup_rojo

# tengo los kda bien calculados en lol2
lista_kda<-c('kda_top_azul','kda_jng_azul','kda_mid_azul','kda_adc_azul','kda_sup_azul','kda_top_rojo','kda_jng_rojo','kda_mid_rojo','kda_adc_rojo','kda_sup_rojo')

lol2<-lol2 %>% select(all_of(lista_kda))
lista_kda_2 <- paste("2",lista_kda, sep='_')
colnames(lol2) <- lista_kda_2

lol[lista_kda_2]<- lol2

# si hay infinito en lol, se coge el valor bien calculado, que está en la variable con 2_
lol$kda_top_azul <- ifelse(lol$kda_top_azul == Inf, lol$`2_kda_top_azul`, lol$kda_top_azul)
lol$kda_jng_azul <- ifelse(lol$kda_jng_azul == Inf, lol$`2_kda_jng_azul`, lol$kda_jng_azul)
lol$kda_mid_azul <- ifelse(lol$kda_mid_azul == Inf, lol$`2_kda_mid_azul`, lol$kda_mid_azul)
lol$kda_adc_azul <- ifelse(lol$kda_adc_azul == Inf, lol$`2_kda_adc_azul`, lol$kda_adc_azul)
lol$kda_sup_azul <- ifelse(lol$kda_sup_azul == Inf, lol$`2_kda_sup_azul`, lol$kda_sup_azul)

lol$kda_top_rojo <- ifelse(lol$kda_top_rojo == Inf, lol$`2_kda_top_rojo`, lol$kda_top_rojo)
lol$kda_jng_rojo <- ifelse(lol$kda_jng_rojo == Inf, lol$`2_kda_jng_rojo`, lol$kda_jng_rojo)
lol$kda_mid_rojo <- ifelse(lol$kda_mid_rojo == Inf, lol$`2_kda_mid_rojo`, lol$kda_mid_rojo)
lol$kda_adc_rojo <- ifelse(lol$kda_adc_rojo == Inf, lol$`2_kda_adc_rojo`, lol$kda_adc_rojo)
lol$kda_sup_rojo <- ifelse(lol$kda_sup_rojo == Inf, lol$`2_kda_sup_rojo`, lol$kda_sup_rojo)

lol<-lol %>% select(-all_of(lista_kda_2))

#repito la imputación realizada antes para tener los datos bien
lol_imputed<-kNN(lol, k=3)

# muestro que se han corregido los nulos. (como ya se producia antes)
sapply(lol_imputed[vars_with_nulls], function(x) sum(is.na(x)))

# muestro que en las imputadas ya no hay estos problemas con las variables de KDA
sapply(lol_imputed[lista_kda], function(x) boxplot.stats(x)$out)

lol_imputed$First_Blood <- as.factor(as.character(lol_imputed$First_Blood))

```

**Se ha sustituido el valor de KDA Inf para las variables por el valor entre 1 que obtuvo ese jugador.** Ahora se distingue mejor un jugador que no murió pero obtuvo muchos asesinatos o asistencias de uno que no influyó mucho en la partida pero simplemente no murió. 

A partir de aquí ya tenemos los datos limpios y seleccionados, por tanto podemos realizar los análisis estadísticos. 


# 4. Análisis de los datos.

Los análisis de datos son una parte imprescindible en este trabajo, debido a que al realizarlos podemos extraer conocimiento de los datos que tenemos en nuestro dataset.
El proceso de analizar los datos no se puede dividir en fases concretas, ya que muchas veces el realizar un análisis o otro depende de los análisis ya realizados y el conocimiento extraído. Por tanto, yo voy a seguir los títulos que se siguen en la práctica, pero de manera que por ejemplo, para la selección de datos voy a utilizar una aplicación de prueba estadística. Los análisis de datos a realizar son:

* Análisis de correlación de las variables con la variable objetivo 'gana'. Este análisis estadístico lo realizo en la fase de selección para seleccionar un dataset reducido que usar más adelante. 
* Estudio de la normalidad y homocedasticidad de las variables.
* Aplicación de un análisis estadístico descriptivo de las variables. 
* Realización de un contraste de probabilidades.
* Realización de un contraste de hipótesis entre dos grupos, que se definirá posteriormente entre que variables en función de las variables seleccionadas y el estudio de la normalidad y la homocedasticidad. 
* Realización de un contraste de hipótesis entre más de dos grupos.
* Desarrollo de un modelo de regresión logística para predecir el ganador de una partida. 

## 4.1 Selección de los grupos de datos que se quieren analizar/comparar.

Para realizar la selección de los grupos de datos que se quieren analizar, podemos hacerlo de diferentes maneras, en definitiva lo importante es seleccionar el conjunto de datos que sea útil para realizar los análisis. En este caso, todavía tenemos muchos datos por cada instancia, así que lo interesante es reducir el conjunto de datos por una reducción de dimensionalidad. 

Por una parte, esto se puede hacer mediante algoritmos como PCA, que aplica una reducción de las dimensiones seleccionando m nuevas variables no correlacionadas entre ellas a partir de las variables del dataset. 
En nuestro caso, para aprovechar la realización de un análisis estadístico, vamos a detectar las variables más correlacionadas con la variable objetivo 'gana'. Seleccionaremos aquellas variables más correlacionadas. De manera que en esta selección hacemos una reducción de la dimensionalidad por la correlación. 

### 4.1.1 OneHotEncoding de variabvles categóricas

Para tener todas las variables numéricas y poder hacer la medida de correlación, hemos de hacer un OneHotEncoding de las variables categóricas. Primero muestro cuales son binarias y cuales son nominales.

```{r,eval=TRUE,echo=TRUE}

# selecciono solo los valores, no la infor de imputacion
lol_imputed<-lol_imputed[,1:ncol(lol)]

# selecciono las variables binarias
vars_2_niveles<-sapply(lol_imputed,function(x) length(levels(x))==2)
vars_2_niveles<-names(vars_2_niveles[which(vars_2_niveles==TRUE)])
print("Las variables binarias son: " )
print(vars_2_niveles)

# selecciono las variables con mas categorias
vars_mas_niveles<-sapply(lol_imputed,function(x) length(levels(x))>2)
vars_mas_niveles<-names(vars_mas_niveles[which(vars_mas_niveles==TRUE)])
print("Las variables nominales son: " )
print(vars_mas_niveles)

```

Por tanto, las variables binarias hemos podido aplicarles un OneHotEncoding sin ningún problema, aunque ahora tenemos las variables duplicadas, ya que para gana, tenemos gana_azul y gana_rojo y estas variables son complementarias, cuando una es 1 la otra es 0. Esto se debe a que la variable gana no podíamos determinar si azul>rojo o rojo>azul, esta variable era nominal y no ordinal.

Ahora con estas variables gana_azul o gana_rojo, realmente podemos interpretar que gana_azul es que el equipo azul gana (=1) o que el equipo azul pierde (=0), y por tanto las variables generadas son ordinales. Además, como la información está duplicada en variables complementarias, podemos eliminar estas. 

**Por tanto, nos quedaremos con la primera_sangre_azul, la primera_torre_azul y nuestra variable objetivo será gana_azul. De manera que en todas estas variables un 1, será que gana el equipo azul y un 0 que pierde el equipo azul (que sabemos, por lógica que es que gana el equipo rojo).**


Para las variables nominales hay varias posibilidades, podemos mantenerlas como nominales y calcular su coeficiente de correlación respecto a gana_azul mediante diferentes posibilidades. **Otra posibilidad es simplemente aplicar OneHotEncoding a las variables, de manera que cada categoría de la variable será una variable nueva y estudiaremos su correlación con la variable gana.**


```{r,eval=TRUE,echo=TRUE}

# elimino las duplicadas
lol_imputed_onehot <- as.data.frame(one_hot(as.data.table(lol_imputed)))
lol_imputed_onehot$gana_rojo<-NULL
lol_imputed_onehot$primera_sangre_rojo<-NULL
lol_imputed_onehot$primera_torre_rojo<-NULL

dim(lol_imputed_onehot)

```

Vemos que por el OneHotEncoding, ahora tenemos 103 variables debido a que hay 3 variables que se han dividido en varias variables. Esto no supone ningún problema porque vamos a aplicar la correlación sobre todas las variables y reducir el dataset a las más correlacionadas. 


### 4.1.2 Cálculo de correlación frente a gana_azul.

Para identificar la correlación de las variables, quiero hacerlo de todas las variables frente a la variable objetivo gana_azul. Primero hemos de identificar que correlación se tiene que calcular entre las variables. 

Actualmente, todas las variables del dataset se encuentran como variables numéricas, aunque algunas de estas sean totalmente numéricas, y otras se puedan identificar como ordinales, como las variables que acabamos de generar. 

Entre variables numéricas, la correlación que se suele calcular es la correlación de Pearson, esta necesita que las variables sean normales. En este estudio, todavía no hemos calculado las propiedades de las variables, pero sabemos que la variable gana_azul, que es la variable objetivo y que va a estar siempre en las correlaciones que queremos calcular no presenta normalidad, puesto que es una variable ordinal, y solo puede presentar 0 o 1 como valores. 

**Por tanto, cuando no se puede garantizar normalidad en alguna de las variables al calcular la correlación, se utiliza la correlación de Spearman. De esta manera, actualmente voy a calcular la correlación de Spearman, independientemente de la normalidad o no del resto de variables, puesto que sé que gana_azul no es normal.**

```{r,eval=TRUE,echo=TRUE}

# selecciono el nombre de las variables menos la objetivo
variables_a_correlacion<-c(colnames(lol_imputed_onehot %>% select(-'gana_azul')))

# calculo las correlaciones de spearman
correlaciones<-as.data.frame(sapply(lol_imputed_onehot[variables_a_correlacion], function(x) cor(x,lol_imputed_onehot$gana_azul, method='spearman')))

colnames(correlaciones)<-'correlacion'

# obtengo el valor absoluto de la correlacion
correlaciones$correlacion_abs<-abs(correlaciones$correlacion)

# las ordeno y selecciono solo aquellas que superan el limite
correlaciones<-correlaciones[order(-correlaciones$correlacion_abs),]
correlaciones_importantes<-correlaciones[which(correlaciones$correlacion_abs>0.5),]
correlaciones_importantes %>% kable()

```

Vemos que al sacar el valor absoluto de las correlaciones, podemos ordenarlas para sacar aquellas variables que más correlacion tienen con la variable objetivo gana. Al seleccionar las variables, definimos el límite de correlación en 0.5 absoluto. 
Las 28 variables que tienen una correlación mayor de 0.5 absoluto, y por tanto utilizaremos en nuestro estudio analítico son:

* El número de torres para los dos equipos. 
* El daño a objetivos para los dos equipos. 
* El número de inhibidores para los dos equipos. 
* El KDA para cada uno de los jugadores de la partida. 
* El número de asesinatos de cada equipo. 
* El número de dragones totales para cada equipo. 
* El número de nashors para cada equipo. 
* El número de dobles asesinatos realizados por cada equipo. 
* El oro al minuto 15 para el equipo rojo. 
* La curación realizada para el equipo rojo. 
* La diferencia de oro al minuto 15. 
* La diferencia de experiencia al minuto 15. 

Es importante destacar que, que todas las variables seleccionadas son individuales o si tienen una pareja han aparecido ambas en la selección, salvo la variable oro_al_15_rojo, que no tiene su pareja oro_al_15_azul y la variable cura_rojo que no tiene su pareja cura_azul. Por tanto las añado manualmente aunque no sobrepasen el límite de selección de correlación. 

```{r,eval=TRUE,echo=TRUE}

correlaciones[which(rownames(correlaciones)=='oro_al_15_azul'),]

correlaciones[which(rownames(correlaciones)=='cura_azul'),]

```

Vemos que la correlación de oro_al_15_azul y cura_azul está lejos del 0.5 siendo 0.397 y 0.356. De igual manera, las añado puesto que son dos variables y le otorgan una "lógica" al dataset. 

#### 4.1.2.1 Estudio correlaciones de variables First_blood, MasValiosoAzul y MasValiosoRojo.

Por último, si miramos las correlaciones vemos que las correlaciones de las variables derivadas de first_blood, MasValiosoAzul y MasValiosoRojo son muy bajas y están lejos del límite, por tanto está claro que pertenecer a una categoría de estas variables no es útil para determinar que equipo gano en la partida. 

```{r,eval=TRUE,echo=TRUE}

require(tibble)
correlaciones<-rownames_to_column(correlaciones, var = "variable") 
correlaciones %>% filter(grepl('MasValioso|First_Blood', `variable`) )

```

Arriba observamos que la correlación absoluta mayor es de 0.11 y por tanto estas variables aportarían muy poco. 

Por si acaso, y para asegurarnos de que aunque cada categoría de las variables no tiene una gran correlación, si usáramos la variable por si misma tampoco tendría correlación mayor de 0.5, vamos a obtener la correlación mediante una regresión lineal para cada variable independiente y gana_azul.
La raiz cuadrada del coeficiente R2 de la regresión se puede usar como coeficiente de correlación, aunque realmente representa la correlación entre los valores reales y las predicciones realizadas por el modelo de regresión. 

```{r,eval=TRUE,echo=TRUE}

# calculo las correlaciones de estas variables con la objetivo calculado el rcuadrado del modelo
model.lm <- lm(lol_imputed_onehot$gana_azul ~ lol_imputed$First_Blood)
paste0("El coeficiente de correlación de FirstBlood sería: ",sqrt(summary(model.lm)$r.squared))

model.lm <- lm(lol_imputed_onehot$gana_azul ~ lol_imputed$MasValioso_rojo)
paste0("El coeficiente de correlación de MasValioso_rojo sería: ",sqrt(summary(model.lm)$r.squared))

model.lm <- lm(lol_imputed_onehot$gana_azul ~ lol_imputed$MasValioso_azul)
paste0("El coeficiente de correlación de MasValioso_azul sería: ",sqrt(summary(model.lm)$r.squared))



```

Vemos que sin duda, la correlación de First_Blood por sí sola es superior a la de sus categorías por separado. De igual manera, su correlación es la mitad del límite, por tanto podemos olvidarnos de esta variable y mantener las 28 variables seleccionadas por el límite más las dos que vamos a añadir por ser pareja de alguna variable seleccionada. Las otras variables siguen teniendo correlaciones muy bajas. 


```{r,eval=TRUE,echo=TRUE}

# selecciono las variables importantes
variables_importantes<-rownames(correlaciones_importantes)
variables_importantes<-c(variables_importantes, 'oro_al_15_azul', 'cura_azul', 'gana_azul')

lol_imputed_onehot<-lol_imputed_onehot[variables_importantes]

dim(lol_imputed_onehot)
```

Vemos que el dataset se ha reducido a 31 variables, que son las 30 variables seleccionadas por correlación más la variable objetivo. 

## 4.2 Comprobación de la normalidad y homogeneidad de la varianza.

Para poder realizar un contraste de hipótesis, ya sea una comparación entre dos grupos o entre más grupos, es necesario comparar la normalidad y homocedasticidad de las variables. 
En caso de que las variables sean normales y tengan homogeneidad de la varianza, se pueden aplicar test paramétricos como la t de Student o ANOVA. Sino, se tendrán que aplicar test no paramétricos como Wilcoxon o Mann-Whitney o Kruskal-Wallis. 

Respecto a la comprobación de normalidad y homocedasticidad, yo voy a realizarlo todo en el conjunto de datos que tenemos actualmente. 

### 4.2.1 Comprobación de la normalidad

Primero compruebo la normalidad de las variables numéricas. Esta claro que la variable objetivo gana_azul no se tiene que estudiar su normalidad puesto que es una variable binaria. 
La normalidad de las variables se comprueba mediante el test de Saphiro-Wilk, su hipótesis nula es que la variable se encuentra distribuída normalmente, por tanto, si su p-valor es menor a 0.05 es que la variable no se encuentra distribuída normalmente. 

De igual manera, por el teorema del límite central a partir de una muestra de más de 30, se puede considerar que la distribución es normal aunque los test como Saphiro-Wilk digan que no.

Por otra parte, para las variables que no son normales habrá que justificar si se normalizan o no.

```{r,eval=TRUE,echo=TRUE}

# configuro los niveles de gana_azul correctamente de nuevo
lol_imputed_onehot$gana_azul<-as.factor(ifelse(lol_imputed_onehot$gana_azul == 1, 'si','no'))
lol_imputed_onehot$gana_azul <- factor(lol_imputed_onehot$gana_azul, levels=c("si", "no") )

# selecciono un dataset solo con las variables numericas
lol_numericas <- lol_imputed_onehot %>% select(where(is.numeric) | where(is.integer))

# obtengo el p-valor del test de normalidad
pvalores<-sapply(lol_numericas, function(x) shapiro.test(x)$p.value)

print("Las variables con distribución normal y sus p-valores son:")
pvalores[which(pvalores>=0.05)]

normales<-names(pvalores[which(pvalores>=0.05)])

print("Las variables sin distribución normal y sus p-valores son:")
pvalores[which(pvalores<0.05)]

nonormales<-names(pvalores[which(pvalores<0.05)])
```

Vemos que las unicas variables con distribución normal son la diferencia de oro en el minuto 15 y la diferencia de experiencia en el minuto 15. Las otras variables están muy lejos de tener una distribución normal al ver sus p-valores. 
Esto lo tendremos en cuenta al hacer contraste de hipótesis.

**Por otra parte, podríamos normalizar los datos y así poder realizar pruebas paramétricas en el los análisis estadísticos. El problema, es que uno de los puntos principales de los análisis estadísticos a realizar es el describir las variables relacionadas con la victoria e identificar como influyen los factores importantes en la victoria, por lo que si normalizamos estas variables:**

**1. la descripción de las variables pierde el sentido, puesto que los valores a describir ya no tienen lógica dentro del juego.**
**2. y encontrar la influencia de los factores en la partida ya no aporta conocimiento puesto que es influencia de los valores normalizados, no de los valores reales, y no podríamos conocer cuanto aporta, por ejemplo, tirar una torre a la victoria.**

**En definitiva, no normalizo las variables que no son normales porque quiero poder establecer las conclusiones del análisis en base a los datos reales del dataset, entendiendo las conclusiones en número que sean lógicos dentro de una partida.**

### 4.2.2 Comprobación de la homocedasticidad.

Partiendo de la normalidad, hay dos maneras de comprobar la homocedasticidad de las variables. Si la variable sigue una distribución normal, la varianza se ha comprobar por el Levene Test, mientras que si la variable no sigue no distribución normal se ha de comprobar la homocedasticidad por el Fligner Test. 
En ambos test, la hipótesis nula asume homocedasticidad de las varianzas, por lo que si el p-valor es de menos de 0.05 se rechaza la hipótesis nula y hay heterocedasticidad de las varianzas. 

Es importante mencionar, que yo voy a obtener la homocedasticidad para las variables numéricas frente a la variable objetivo gana_azul. 

```{r,eval=TRUE,echo=TRUE}

# compruebo la homocedasticidad para las variables normales
pvalores<-sapply(lol_numericas[normales], function(x) leveneTest(x ~ lol_imputed_onehot$gana_azul)$`Pr(>F)`[1])

print("Las variables con distribución normal, tienen todas homocedasticidad porque sus p-valores son:")
pvalores[which(pvalores>=0.05)]

normales_homocedasticidad<-names(pvalores[which(pvalores>=0.05)])

# compruebo la homocedasticidad para las variables no normales
pvalores<-sapply(lol_numericas[nonormales], function(x) fligner.test(x ~ lol_imputed_onehot$gana_azul)$p.value)

print("Las variables sin distribución normal, que no tienen homocedasticidad y sus p-valores son:")
pvalores[which(pvalores<0.05)]

nonormales_heterocedasticidad<-names(pvalores[which(pvalores<0.05)])

print("Las variables sin distribución normal, que tienen homocedasticidad y sus p-valores son:")
pvalores[which(pvalores>=0.05)]

nonormales_heterocedasticidad<-names(pvalores[which(pvalores>=0.05)])

```


Por tanto, podemos concluir que las 2 únicas variables con distribución normal, además tienen homocedasticidad debido a que sus p-valores son superiores 0.05, son la diferencia de oro al 15 y la diferencia de experiencia al 15.

Por otra parte, el resto de variables no tienen una distribución normal, pero hay un pequeño grupo de variables que si que tiene varianzas iguales para los diferentes grupos en función de la variable objetivo, estas son el daño a objetivos por parte del equipo rojo y azul, el número de torres del equipo rojo, el oro al 15 del equipo azul y la curación del equipo azul. El resto de variables presentan heterocedasticidad. 

## 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos.

Hay que recordar que la primera prueba estadística ya la hemos realizado en la selección de atributos con el objetivo de reducir la dimensionalidad mediante la identificación de la correlación de las diferentes variables con la variable objetivo. 

Las pruebas a realizar son: 

* Análisis estadístico descriptivo.
* Contraste de proporción de victoria del azul es superior al rojo.
* Contraste de que el daño a objetivos por parte del equipo azul es superior cuando gana a cuando pierde.
* Contraste de si la diferencia de experiencia en el minuto 15 es igual independientemente de si gana o pierde el equipo azul. 
* Contraste de diferencia de KDA entre posiciones para el equipo ganador.


### 4.3.1 Análisis estadístico descriptivo. 

Antes de realizar análisis estadísticos más profundos para determinar características del dataset, es importante realizar un análisis descriptivo que nos permita identificar aspectos importantes del conjunto de datos. Dentro de este análisis descriptivo se podría incluir el estudio de normalidad y varianza ya realizado hasta ahora. Por tanto, me voy a rescindir a estudiar el sumario del conjunto de datos y representar las variables en gráficas. **A pesar de que las gráficas deberían de pertenecer al ejercicio 5, es lógico que para estudiar el análisis descriptivo del conjunto de datos representemos un histograma de las variables, por tanto desarrollo los histogramas de las variables en este apartado.**

Para realizar este análisis y no abrumarnos, vamos a ir comparando las variables en función de su ámbito.

#### 4.3.1.1 Descripción de las objetivos, daño a objetivos, y ganar

Debido a que la variable gana_azul es la variable objetivo la introduzco en el análisis de los objetivos. Además así la podemos tener presente en todos los análisis para describir comportamientos. 

```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}

# Plot del histograma
plot_hist<-function(x)
{
  print(ggplot(data=lol_imputed_onehot, aes(x=unlist(lol_imputed_onehot[x]))) +
  geom_histogram(
                 col="red",
                 fill="green",
                 alpha = .2) +
  labs(title=paste0("Histograma de ",x)) +
  labs(x=x, y="Frecuencia"))
}

vars <- c('num_torres_azul', 'num_torres_rojo', 'DamageObjectives_azul','DamageObjectives_rojo','inhibs_azul','inhibs_rojo', 'gana_azul')

summary(lol_imputed_onehot[vars])

# calculo el porcentaje de victorias en función del equipo
gana_azul_porcentaje<-nrow(lol_imputed_onehot[which(lol_imputed_onehot$gana_azul=='si'), ])/nrow(lol_imputed_onehot)
paste0("El equipo azul gana un ", round(gana_azul_porcentaje,3), " y el rojo un ", 1-round(gana_azul_porcentaje,3))

# hago los plots de los histogramas
invisible(sapply(vars[1:(length(vars)-1)],plot_hist))



```

Lo primero que llama la atención es que el equipo azul gana considerablemente más que el equipo rojo. 
Esto puede ser pura coincidencia o puede ser debido a que el equipo del lado azul tenga una ventaja. Generalmente, en el juego se prefiere jugar como el equipo azul, debido a que selecciona el primer campeón de la partida y que tiene un mejor acceso al lugar donde está el nashor. Sin embargo el rojo tiene el último campeón y mejor acceso al lugar del dragón.  

Respecto al resto de variables: 

1. Respecto a las variables de torres:
* Coinciden en el máximo y en el mínimo, esto es porque hay partidas donde un equipo no destruye torres y otras partidas donde un equipo destruye todas las torres (11). 
* Vemos como tanto en los cuartiles como en la media y mediana se observa que los valores de torres del equipo azul son superiores a los del rojo. Esto puede ser derivado por la ventaja que hemos visto que tiene el equipo azul, ya que sabemos que las variables tienen alta correlación con la variable objetivo, y por tanto, cuanto más torres destruye el equipo azul, más posibilidades de ganar la partida. 
* Además, al estudiar los histogramas vemos que la distribución de las torres es una distribución bimodal, donde se ve claramente que un equipo consigue normalmente muchas torres o muy pocas, pero un valor torres intermedio no suele ocurrir. Esto se debe a que un equipo gana y consigue muchas torres o pierde y consigue pocas torres. Es dificil que ambos equipos consigan un mismo numero de torres. 

2. Respecto a la variable de daño a objetivos:
* Se observa igual que en torres que los valores de tendencia central son superiores en el equipo azul, lo que posiblemente se debe a que el equipo azul gana más. 
* En el estudio de los histogramas de nuevo vemos que ambas variables de daño a objetivos son bimodales. Hay dos "montañas" en la distribución, lo normal es que en la variable de daño a objetivos azul, sea mayor cuando el equipo azul gane y menor cuando el equipo rojo (al contrario en la variable daño a objetivos rojo), lo que hace que se generen estas dos montañas. 
* Podemos hacer un contraste de hipótesis donde comprobemos si la media de daño a objetivos azul es la misma cuando gana el equipo azul o el rojo y posiblemente vemos como la media cuando gane cae en la montaña derecha y la media cuando pierde el azul cae en la montaña izquierda. 

3. Respecto a las variables de inhibidores destruidos por el equipo: 
* La diferencia entre equipo azul y rojo en el sumario se aprecia menos, aun así es interesante comentar como la mediana de inhibidores del rojo es 0, es decir que en más de la mitad de partidas ni consiguen un inhibidor, algo que es indispensable para ganar. Por otra parte la mediana del equipo azul si es 1. Como aspecto interesante, vemos como el máximo de inhibidores del rojo es 6 mientras que el del equipo azul es 5. Esto se puede deber a que el equipo azul gana antes de que sea necesario volver a destruir los 3 inhibidores. 
* La variable es numérica, no categórica, aunque vemos que solo pueden ser enteros y los valores en el dataset para las variables son pocos de 0 a 6 (o 5). En el histograma por tanto, podemos definir que la distribución de la variable es exponencial, ya que las primeras categorias tienen mucha mas posibilidad de ocurrir que las últimas. Esto se debe a que el equipo que gana mínimo tiene que destruir un inhibidor para ganar, pero no es necesario más, por lo que incluso cuando se ganan partidas, se puede ganar con un solo inhibidor.




#### 4.3.1.2 Descripción de los KDA


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}



vars <- c('kda_top_azul', 'kda_jng_azul', 'kda_mid_azul','kda_adc_azul','kda_sup_azul','kda_top_rojo', 'kda_jng_rojo', 'kda_mid_rojo','kda_adc_rojo','kda_sup_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

Para los KDA podemos comentar: 


* Al ver el sumario, pdoemos ver que según la posición hay un KDA mayor o menor, es decir que el KDA del top azul o rojo son más o menos parecidos, igual que el KDA de los junglas, de los medios, de los adc o de los support. Vemos por tanto, que de media, los jugadores con peor KDA son el top, seguido del support. En medio se encuentra el jungla, y los mejores KDA los tienen los medios, y sobretodo los ADC.
* Por otra parte, al estudiar los histogramas, vemos que todos tienen la misma distribución, aparentemente una distribución lognormal, donde el valor que más aparece está muy cerca al límite inferior (que es 0), pero que la distribución se extiende mucho a valores muy superiores que esta moda (cada vez con menor posibilidad de aparación). Es decir, que lo normal es que el KDA de un jugador sea entre 1 y 2, pero que el valor de este KDA puede superar de 10 o 15 sin problema. 



#### 4.3.1.3 Descripción de los asesinatos


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}


vars <- c('num_asesinatos_azul', 'num_asesinatos_rojo', 'double_k_azul','double_k_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al estudiar los asesinatos por equipos podemos ver:

* El número de asesinatos por equipo parece ser similar entre ambos equipos. Los valores son similares, vemos que ambos equipos de mediana tienen 12 asesinatos, y aunque el equipo azul tiene una media superior apenas se diferencian, por lo que parece que independientemente de la partida y su ganador, ambos equipos consiguen varios asesinatos. Eso sí, está claro que hay partidas donde algún equipo consigue 0 asesinatos, porque a veces un equipo es muy superior al otro. 
* Al ver el histograma, podemos ver como la distribución es positiva asimétrica, donde no se puede asegurar una forma concreta con nombre, Vemos de nuevo que los asesinatos suelen ser un valor entre 5 y 20, para ambos equipos y que pocas veces se obtienen menos o más asesinatos. 
* En comparación con las variables de daño a objetivos o torres, al ver esta distribución y no una distribución bimodal, vemos que no es tan claro que conseguir asesinatos repercute tan claramente como conseguir torres o objetivos en el resultado de la partida. En la distribución bimodal queda claro que normalmente caes en una montaña o en otra y en función de eso pierdes o ganas, en esta distribución puedes ganar una partida habiendo obtenido pocos asesinatos. 

2. Al estudiar las dobles kill por equipos podemos ver: 

* La variable es parecida a los inhibidores. Al mirar los histogramas es casi una variable categórica, aunque claramente es numérica porque se pueden conseguir infinitos dobles asesinatos en una partida. La distribución por tanto es exponencial, donde es muy posible que no se consigan 0 asesinatos dobles, y aumentar en 1 el valor de asesinatos dobles es menos probable. 
* Al ver el sumario vemos que ambas variables para el equipo azul y el rojo son muy parecidas, con misma mediana y medias muy similares. Ocurre por tanto como con asesinatos, que aunque como ya sabemos que su correlación es positiva para el azul y negativa para el rojo, y que por tanto se consiguen más asesinatos cuando se gana, puede ser que más dobles asesinatos no signifique nada para ganar. 




#### 4.3.1.4 Descripción de los monstruos de la jungla


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}


vars <- c('num_dragones_azul', 'num_dragones_rojo', 'num_nashors_azul','num_nashors_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al ver los dragones de ambos equipos podemos ver que:

* Al contrario que la mayoría de variables, en caso de los dragones la media es superior en el lado rojo. Esto se debe principalmente a algo que ya comentamos antes, y es que el lado rojo tiene ventaja en el lado del dragón. Por lo demás sus valores son parecidos.
* Al observar los histogramas, vemos de nuevo que aunque las variables son numéricas tienen un rango de valores bastante corto. En general destaca que la mayoría de partidas los equipos tienen entre 0 y 4 dragones y es muy dificil que pasen de esta cifra, esto se debe a que a partir de que un equipo tiene 4 dragones, obtiene una ventaja muy grande que hace que las partidas acaben pronto. 

2. Al ver los nashor de ambos equipos podemos ver que: 
* En este caso, vemos que la media de nashor es superior en el equipo azul, por su mayor capacidad de ganar y por su ventaja. Además vemos que incluso su tercer cuartil en ambos equipos es 1, mientras que la máxima son 4 y 3. Es decir, que normalmente un equipo consigue 0 o 1 nashor por partida, pero que se puede llegar a obtener muchos nashors, esto será normalmente en partidas igualadas. 
* Al ver el histograma, de nuevo vemos lo comentado, que normalmente un equipo tiene 0 o 1 nashors y es muy dificil obtener más. 




#### 4.3.1.5 Descripción del oro y experiencia


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}



vars <- c('oro_al_15_azul', 'oro_al_15_rojo', 'diff_oro_al_15','diferencia_exp')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al comprobar el oro al minuto 15 de ambos equipos:

* En el sumario podemos comprobar como normalmente la ventaja en media y mediana la tiene el equipo azul, derivado posiblemente de que el equipo azul gana más partidas.
* Por otra parte vemos como el rango entre el mínimo y el máximo son unos 10000 de oro. Por lo tanto es muy importante conseguir cuanto más oro mejor, porque el valor superior es un 50% más del valor mínimo. 
* Al ver los histogramas, vemos como a pesar de que el test de saphiro-wilk dió que las variables no son normales, su distribución es bastante normal, y solo está un poco movida al mínimo. 

2. Al comprobar la diferencia de oro al minuto 15:
* Vemos como el valor mínimo y máximo son parecidos, lo que indica que el peor equipo rojo y el peor equipo azul han sido parecidos. Lo más importante es ver como el equipo azul normalmente tiene ventaja en esta variable puesto que la mediana y la media son positivas, y esto indica que el equipo azul tiene ventaja. 
* La distribución es normal, se aprecia totalmente en el histograma. 


#### 4.3.1.6 Descripción de la curación


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}


vars <- c('cura_azul', 'cura_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al estudiar la curación de los equipos vemos que:

* Estudiando el sumario, el rango de curación de ambos equipos es parecido, aunque es más extremos en los equipos azules. Por otra parte, el máximo de curación por minuto está bastante separado de la media y mediana, sobre todo comparando con el mínimo, es muy extremo este valor respecto a la distribución.
* Si estudiamos las distribuciones, vemos que ambas son parecidas, y están bastante movidas hacia el extremo inferior. Por lo que podemos ver que normalmente ambos equipos tienen una curación entre 500 a 1250 por minuto. 


### 4.3.2 Contraste de hipótesis

A continuación realizo varias pruebas de contraste de hipótesis: 

#### 4.3.2.1 Contraste de proporción de victoria del azul es superior al rojo

Ya hemos visto que el equipo azul parece que tiene una cierta ventaja, puesto que este equipo ha ganado más que el equipo rojo. Por tanto puede ser interesante estudiar si la diferencia en la variable gana_azul es significativa o no. 

Voy a utilizar **un contraste de hipótesis sobre la proporción de victoria en la variable gana_azul**. Las variables binarias, al estudiar su proporción, siguen una distribución de Bernoulli de parametro p, sobre la que quiero hacer un contraste. Cuando la n es grande, sobretodo n>30, esta distribución de Bernoulli, se puede aproximar, mediante las probabilidades a una distribución normal, por esto podemos aplicar los conceptos de la normal z. El contraste es unilateral, puesto que quiero comprobar si la proporcion de victoria del equipo azul es superior a la proporción de victoria del equipo rojo, sino es inferior o igual.

Por tanto, las hipótesis de este contraste son:

$H_{0} : p_{gana_azul} = p_{gana_rojo}$ -> $p_{gana_azul} = 1/2$   
$H_{1} : p_{gana_azul} > p_{gana_rojo}$ -> $p_{gana_azul} > 1/2$

```{r,eval=TRUE,echo=TRUE}

# hago el test de proporciones
prop.test( table(lol_imputed_onehot$gana_azul), conf.level=0.95, alternative = 'greater')



```

El p-valor es 0.1379, por lo que rechazamos la hipótesis alternativa y no podemos rechazar la hipótesis nula. **De esta manera se concluye que la proporción de victoria del equipo azul no es superior a la proporción de victoria del equipo rojo con un 95% de confianza.**
De hecho, vemos que el intervalo de confianza es de 0.4888 hasta 1, solo si fuera de más de 0.5 hasta 1, podríamos decir que la proporción de victoria del equipo azul es superior. 

Por tanto, a pesar de que en nuestro dataset hay más victorias del equipo azul, no podemos asegurar que el equipo azul tiene una ventaja solo por ser lado azul. 

#### 4.3.2.2 Comprobación de que el daño a objetivos por parte del equipo azul es superior cuando gana a cuando pierde. 

Una vez que ya hemos estudiado la diferencia entre victorias, podemos pasar a estudiar aspectos de la partida en función de si un equipo o otro gana. En este caso **vamos a estudiar un contraste de hipótesis sobre la variable DamageObjectives_azul en función de los grupos de gana_azul.**

Ya hemos realizado las pruebas de normalidad y de homocedasticidad. Para esta variable, ya hemos comprobado que su distribución no es normal (mediante la prueba de Saphiro-Wilk), de hecho, al estudiar su histograma hemos visto que la distribución es bimodal. Por otra parte, hemos visto mediante el test de fligner que su varianza en función del grupo de gana_azul es igual entre los grupos. 

Por tanto, ahora podemos aplicar el test no paramétrico Wilcoxon y comprobar si la distribución de daño a objetivos por parte del equipo azul en función del ganador es la misma o no. Además, como la distribución de varianza es la misma, si la distribución de un grupo es mayor, su mediana será mayor. 

En el test de Wilcoxon, las hipotesis se fundamentan en estudiar la posibilidad de que un elemento de una población sea mayor que un elemento de otra población. En caso de que tengamos dos poblaciones iguales, la probabilidad para ambas poblaciones será de 0.5. Por tanto, nosotros queremos comprobar si las posibilidades de que el daño a objetivos por parte del equipo azul cuando gana sean mayores que cuando pierde, o que sean iguales estas posibilidades.

$H_{0} : P(x_{i} > y_{i}) = 0.5$    
$H_{1} : P(x_{i} > y_{i}) > 0.5$ 

```{r,eval=TRUE,echo=TRUE}

# divido en dos datasets, el que gana el equipo azul y el que pierde
gana<-lol_imputed_onehot[which(lol_imputed_onehot$gana_azul == 'si'),]
pierde<-lol_imputed_onehot[which(lol_imputed_onehot$gana_azul == 'no'),]

# hago el test no parametrico
wilcox.test(gana$DamageObjectives_azul, pierde$DamageObjectives_azul, alternative = "greater", mu = 0,paired = FALSE, conf.int = 0.95)





```

Como vemos, el p-valor es muy muy pequeño, por lo que se rechaza la hipótesis nula y se acepta la hipótesis alternativa. Por tanto, **la distribución del daño del equipo azul a objetivos es superior que la distribución del daño a objetivos del equipo rojo con un 95% de confianza.** Algo que en realidad, ya sospechabamos al ver la correlación entre las variables. Ahora hemos comprobado que hay significancia estadística. 

Esto lo comprobamos más adelante en el apartado 5, al observar la distribución de la variable en función de los grupos que se generan por gana_azul y al ver que las medianas son diferentes. 

#### 4.3.2.3 Comprobación de si la diferencia de experiencia en el minuto 15 es igual independientemente de si gana o pierde el equipo azul. 

Otro aspecto interesante de la partida respecto a quién gana es la diferencia de experiencia. En este caso **vamos a estudiar un contraste de hipótesis sobre la variable diferencia_exp en función de los grupos de gana_azul.**

Ya hemos realizado las pruebas de normalidad y de homocedasticidad. Para esta variable, hemos comprobado mediante el test de Saphiro-Wilk que tiene una distribución normal y mediante el test de Levene que la varianza en función del grupo gana_azul es igual entre los grupos. 

Por tanto, ahora podemos aplicar el t test para estudiar si la media de diferencia de experiencia para un grupo es la misma que la media de diferencia de experiencia para el otro grupo.
En caso de que sean iguales, será que la diferencia de experiencia es parecida independientemente de quién gane y que por tanto no importa tener una ventaja de experiencia en la partida.

Las hipótesis son: 

$H_{0} : \mu_{1} = \mu_{2}$ ->  $\mu_{1} - \mu_{2} = 0$   
$H_{1} : \mu_{1} \neq \mu_{2}$  ->  $\mu_{1} - \mu_{2} \neq 0$

```{r,eval=TRUE,echo=TRUE}

# hago el t test
t.test(gana$diferencia_exp, pierde$diferencia_exp, alternative = "two.sided")


```

Vemos que el p-valor es 2.2e-16, es decir, muy pequeño. Esto significa que hemos de rechazar la hipótesis nula y no podemos rechazar la hipótesis alternativa. Por tanto **la media de diferencia de experiencia cuando gana el equipo azul, es diferente a cuando gana el equipo rojo**. Este resultado es lógico puesto que la variable ha superado el filtro de correlación, y por tanto ya sabíamos que la diferencia de experiencia tenía una correlación positiva con el equipo azul para ganar. 


#### 4.3.2.4 Contraste de diferencia de KDA entre posiciones para el equipo ganador.

A continuación, **voy a estudiar un contraste de hipótesis entre más de dos grupos, concretamente la diferencia de KDA entre las diferentes posiciones, pero solo para el equipo ganador de la partida.**

De esta manera, primero hemos de generar el dataset para estudiar esto. 

```{r,eval=TRUE,echo=TRUE}

# obtengo todos los kda en un dataset
todos_kdas<-gana['kda_top_azul']
colnames(todos_kdas)<-'kda'
todos_kdas$posicion<-as.factor('top')

variable<-gana['kda_jng_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('jng')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_mid_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('mid')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_adc_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('adc')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_sup_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('sup')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_top_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('top')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_jng_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('jng')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_mid_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('mid')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_adc_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('adc')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_sup_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('sup')
todos_kdas<-rbind(todos_kdas, variable)

```

Una vez se ha generado el dataset, con una variable que tiene el kda y otra la posición para los jugadores de los equipos que ganan. Vamos a estudiar la normalidad y la homocedasticidad de las variables. 

```{r,eval=TRUE,echo=TRUE}

# hago el test de shapiro para comprobar la normalidad
shapiro.test(todos_kdas$kda)

```

Vemos que el shapiro test indica que el p-valor es muy pequeño, y por tanto, que la distribución de la variable no es normal. 
Si estudiamos la distribución mediante un histograma:


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}

plot_hist_2<-function(x)
{
  print(ggplot(data=todos_kdas, aes(x=unlist(todos_kdas[x]))) +
  geom_histogram(
                 col="red",
                 fill="green",
                 alpha = .2) +
  labs(title=paste0("Histograma de ",x)) +
  labs(x=x, y="Frecuencia"))
}

plot_hist_2('kda')
```

Vemos que claramente, la distribución no es normal ya que podría ser una distribución desviada hacía los valores menores. Donde evidentemente, vemos como los valores que más aparacen para los kda de los equipos ganadores están entre 3 y 9.

A continuación estudiamos la varianza mediante un test de fligner para estudiar si hay homocedasticidad de las varianzas. 

```{r,eval=TRUE,echo=TRUE}

# compruebo la homocedasticidad
fligner.test(kda ~ posicion, data = todos_kdas)

```

Vemos que el p-valor es menor de 0.05, por tanto podemos concluir que no hay homocedasticidad entre las varianzas de kda en función de la posición de cada jugador. 

Debido a estos resultados, vamos a estudiar si la distribución del kda a lo largo de las diferentes posiciones es la misma para los equipos que ganan. Y lo realizamos con un kruskal.test, que es un test no paramétrico. 

El test de Kruskal-Wallis, es un test no paramétrico con las siguientes hipotesis: 
$H_{0} :$ Las 5 distribuciones vienen de la misma población.
$H_{1} :$ Las 5 distribuciones NO vienen de la misma población.

```{r,eval=TRUE,echo=TRUE}

# hago el kruskal test
kruskal.test(kda ~ posicion, data = todos_kdas)

```

Al obtener un p-valor tan inferior a 0.05 podemos concluir con un 95% de confianza que rechazamos la hipótesis nula y se acepta la hipótesis alternativa. **Por tanto, las 5 distribuciones de KDA en función de la posición del jugador no vienen de la misma población. Es decir, que las distribuciones son diferentes.**

Una vez hemos obtenido esto, puede ser interesante estudiar las diferencias en función de los grupos de KDA por posición, para encontrar que distribución de KDA es significativamente diferente respecto a las otras. 

Para ello se puede realizar un pairwise wilcoxon test, donde nos proporciona un p-valor para cada combinación de grupo de KDA en función de la posición. 

```{r,eval=TRUE,echo=TRUE}

# compruebo diferencias entre distribuciones con el pairwise
pairwise.wilcox.test(x = todos_kdas$kda, g = todos_kdas$posicion )

```

Vemos como el kda del top, es significativamente diferente respecto a los otros, igual que ocurre para el adc (utilizando una significancia del 95%). Por otro lado, el jng no es significativamente diferente ni a mid ni a sup, pero entre mid y sup si que son significativamente diferentes. De hecho, si vemos por el p-valor, el mid está tiene un p-valor mayor para igualdad con el adc que con el sup. 

**Por tanto, aplicando la lógica, el kda del top es significativamente inferior que el resto, el del adc significativamente superior. El del jungla no se diferencia significativamente del mid ni del support, pero el mid sí que del support, pareciendose más al del adc. Por tanto, un orden lógico derivado de estos p-valores es:**
**top<sup<=jng<=mid<adc**


### 4.3.3 Regresión logística para predecir que equipo gana.

Ahora que ya hemos realizado varios contrastes de hipótesis y conocemos un poco más sobre el dataset y sus comparaciones, **podemos desarrollar un modelo de regresión logística para predecir el ganador de la partida.** 

Vamos a hacer por tanto un modelo supervisado, con su conjunto de entrenamiento y test, donde la variable objetivo sea gana_azul, y el resto de variables sean variables independientes en el modelo.

Primero hay que subdividir el dataset en entrenamiento y test: 

```{r,eval=TRUE,echo=TRUE}
require(caret)
require(questionr)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
require(MASS)

# configuro correctamente el ganador
lol_imputed_onehot$gana_azul <- factor(lol_imputed_onehot$gana_azul, levels=c("no", "si"))

# divido el dataset en 66% para el entrenamiento y 33% para el test
set.seed(42)
trainIndex <- createDataPartition(lol_imputed_onehot$gana_azul, p = .66, 
                                  list = FALSE, 
                                  times = 1)

Train <- lol_imputed_onehot[ trainIndex,]
Test  <- lol_imputed_onehot[-trainIndex,]


```

A continuación se entrena el modelo y estudiamos su summary.

```{r,eval=TRUE,echo=TRUE}

# hago el modelo de regresión logistica
glm_train<- glm(gana_azul ~ ., data=Train, family = "binomial")

summary(glm_train)


```

Al ver el summary, vemos que la métrica AIC es muy pequeña, por lo tanto el ajuste del modelo a la variable objetivo es bastante bueno y además, que la desviación de residuales es ínfima. Eso sí, también se ha de comentar que se han realizado 25 iteraciones de Fisher, lo que indica junto con una desviación residual tan pequeña pero un AIC pequeño pero no de 0, que la complejidad del modelo es bastante grande respecto a la bondad del ajuste. 

Esto también se puede apreciar en el p-valor de las variables. Y es que todos los p-valores son 1 o 0.999. Es decir, que el modelo puede hacer una predición buena, pero el coeficiente de regresión de las variables no es nada seguro. 
En definitiva, esto se debe a que tenemos varias variables con una correación muy alta, algunas incluso casi separan perfectamente el ganador. 

Realizo las predicciones del modelo para estudiar su desempeño, no estudio sus odds ratio porque los p-valores son todos de 1. 



```{r,eval=TRUE,echo=TRUE}

# se hacen las predicciones para el test
predicciones<- predict(glm_train,Test, type="response")
predicciones <-as.factor(ifelse(predicciones>0.5,'si','no'))

# calculo la matriz de confusion
confmatrix<- confusionMatrix(predicciones,Test$gana_azul, positive = 'si' )
confmatrix



```

Al estudiar los resultados del modelo y su matriz de confianza, vemos como el acierto es altísimo en el conjunto de test, de un 97.6% de acierto, con una sensitividad del 98.17 para predecir si el equipo azul gana la partida. En total se equivoca solo en 5 partidas de las más de 200 del conjunto de test.

Por tanto, hemos obtenido un modelo muy bueno para predecir, pero que no podemos estudiar sus odds ratio, y por tanto no podemos estudiar las variables que influyen en esta predicción. 



#### 4.3.3.1 Regresión logística para identificar los factores que influyen en la victoria de un equipo.

Para poder estudiar las variables que influyen en la predicción, voy de nuevo a realizar una regresión logística donde en vez de predecir si gana el equipo azul o pierde (equivalente a ganar el rojo) , se predice si un equipo gana o pierde, solo con sus datos y sin tener en cuenta los datos del equipo rival, convirtiendo el dataset a un dataset más sencillo, con menos variables, donde cada instancia son los valores de un equipo.   

Generamos este dataset y hago la partición en train y test: 

```{r,eval=TRUE,echo=TRUE}

# genero el nuevo dataset con un equipo por instancia
azul<-lol_imputed_onehot %>% dplyr::select(contains("azul")| contains("exp")| contains("diff")) 
colnames(azul)<-str_replace(colnames(azul),'_azul','')
rojo<-lol_imputed_onehot %>% dplyr::select(contains("rojo")| contains("gana") | contains("exp")| contains("diff")) 
colnames(rojo)<-str_replace(colnames(rojo),'_rojo','')
colnames(rojo)<-str_replace(colnames(rojo),'_azul','')
rojo$gana<- ifelse(rojo$gana == 'si', 'no', 'si')
rojo$diferencia_exp<- -(rojo$diferencia_exp)
rojo$diff_oro_al_15<- -(rojo$diff_oro_al_15)


equipos <-rbind(azul, rojo)

# divido el dataset
set.seed(42)
trainIndex <- createDataPartition(equipos$gana, p = .66, 
                                  list = FALSE, 
                                  times = 1)

Train2 <- equipos[ trainIndex,]
Test2  <- equipos[-trainIndex,]
```

Ahora genero el modelo y estudio su summary. 

```{r,eval=TRUE,echo=TRUE}
#genero el nuevo modelo
glm_train2<- glm(gana ~ ., data=Train2, family = "binomial")

summary(glm_train2)

```
 
Ahora vemos que aunque la bondad del ajuste no es tan buena como antes, ya que el AIC y la desviación de residuales son mayores, la diferencia entre ellos no es tán grande y las iteraciones de Fisher son solo 10. Por lo que ahora la bondad ha disminuido, pero la complejidad del modelo ha disminuido mucho, hasta el punto de que ahora es interpretable. 

En el summary podemos ver como los p-valores ya no son de 1, y que hay varias variables que salen significativas, estas variables son el número de torres, el kda del adc, el kda del jng y el kda del sup. 
Eso significa que el número de torres conseguido y el kda de adc, jng y sup es muy influyente en la partida, y por tanto para asegurarse una victoria tendremos que centrarnos en estas variables.


De esta manera, estas variables son las que sin duda influyen en la predicción de manera significativa. Pero aun así, podemos estudiar los odds ratio de todas las variables. Esto lo realizamos en el punto 5. 
Ahora, realizo las predicciones del modelo para evaluar si ha disminuido mucho la capacidad de acierto sobre el conjunto de test. 

```{r,eval=TRUE,echo=TRUE}

# hago las predicciones para el test
predicciones<- predict(glm_train2,Test2, type="response")
predicciones <-as.factor(ifelse(predicciones>0.5,'si','no'))

# calculo la matriz de confianza
confmatrix<- confusionMatrix(predicciones,Test2$gana , positive = 'si' )
confmatrix

```

Vemos como el acierto del modelo es de 96.88%, menos de un punto de diferencia con el modelo anterior, pero en este caso con este modelo hemos podido identificar que variables son las más influyentes en la predicción del modelo. El modelo por tanto es muy bueno en identificar si un equipo va a ganar independientemente de lo que ha conseguido el equipo contrario. 


# 5. Representación de los resultados a partir de tablas y gráficas. 

Ya hemos realizado muchos análisis estadísticos, pero ahora es importante representar los resultados obtenidos en gráficas y tablas. 

Es importante destacar que los gráficos para las variables del dataset final, que hacen referencia a la distribución de la variables y que son útiles para el análisis estadístico descriptivo ya se han realizado en el punto 4. A continuación desarrollo los gráficos para el resto de puntos. 

Por otra parte, en este punto se incluyen los gráficos referentes a los contrastes de hipótesis realizados, y a los odds ratio y curvas ROC de la regresiones logísticas.

## 5.1 Compración distribución de la variable DamageObjectivos_azul en función del grupo gana_azul

Hemos realizado un contraste de hipótesis de la variable DamageObjectivos_azul respecto al grupo gana_azul y hemos encontrado que el daño a objetivos por parte del equipo azul cuando es gana es superior a cuando pierde. En estas gráficas se estudia visualmente la distribución de la variable en función de ganar o perder por parte del equipo azul. 

```{r,eval=TRUE,echo=TRUE}

# plot de histograma
lol_imputed_onehot %>% 
  ggplot(aes(x=DamageObjectives_azul, fill =gana_azul )) +
  geom_histogram(color="black", alpha=0.7, position = 'identity')+
  geom_vline(xintercept = median(gana$DamageObjectives_azul), color='blue', size=1)+
  geom_text(aes(x=median(gana$DamageObjectives_azul), label="\nMediana cuando gana azul", y=15), colour="blue", angle=90, text=element_text(size=9)) +
  geom_vline(xintercept = median(pierde$DamageObjectives_azul), color='red', size=1)+
  geom_text(aes(x=median(pierde$DamageObjectives_azul), label="Mediana cuando pierde azul\n", y=15), colour="red", angle=90, text=element_text(size=9)) 

# boxplot
lol_imputed_onehot %>% 
  ggplot(aes(y=DamageObjectives_azul, x =gana_azul, fill=gana_azul)) +
  geom_boxplot(color="black", alpha=0.7, position = 'identity')



```

Como se observa, la distribución y la mediana de daño a objetivos por parte del equipo azul, cuando gana es claramente superior a cuando pierde. Estudiando los boxplot tambien vemos como los grupos son completamente diferentes y apenas se solapan en las cajas (del primer al tercer cuartil de cada distribución). Se observan practicamente dos poblaciones distintas que apenas se solapan. 

Por tanto, visualmente, se puede entender claramente la conclusión obtenida en el contraste de hipótesis. 

## 5.2 Compración distribución de la variable diferencia_exp en función del grupo gana_azul

Hemos realizado un contraste de hipótesis de la variable diferencia_exp respecto al grupo gana_azul y hemos encontrado que la diferencia de experiencia cuando gana el equipo azul es diferente a cuando pierde. En estas gráficas se estudia visualmente la distribución de la variable en función de ganar o perder por parte del equipo azul. 

```{r,eval=TRUE,echo=TRUE}

# plot de histograma
lol_imputed_onehot %>% 
  ggplot(aes(x=diferencia_exp, fill =gana_azul )) +
  geom_histogram(color="black", alpha=0.7, position = 'identity')+
  geom_vline(xintercept = mean(gana$diferencia_exp), color='blue', size=1)+
  geom_text(aes(x=median(gana$diferencia_exp), label="\nMedia cuando gana azul", y=15), colour="blue", angle=90, text=element_text(size=9)) +
  geom_vline(xintercept = mean(pierde$diferencia_exp), color='red', size=1)+
  geom_text(aes(x=median(pierde$diferencia_exp), label="Media cuando pierde azul\n", y=15), colour="red", angle=90, text=element_text(size=9))
  
# boxplot
lol_imputed_onehot %>% 
  ggplot(aes(y=diferencia_exp, x =gana_azul, fill=gana_azul)) +
  geom_boxplot(color="black", alpha=0.7, position = 'identity')

```

Al ver tanto los histogramas como los boxplots, vemos gráficamente que claramente la media de diferencia de experiencia cuando gana el equipo azul es diferente que cuando pierde. Vemos como las distribuciones ahora están más solapadas que en el contraste de hipótesis anterior, pero igualmente los máximos de diferencia en experiencia pertenecen a partidas que gana el equipo azul y los mínimos a partidas que pierde. 

Podemos ver como apenas hay alguna partida que llega a ganar el azul aun con -3000 de diferencia de experiencia y lo contrario perdiendo. 

En los boxplots vemos con más claridad que los grupos a penas se solapan, porque solo coinciden un poco entre el primer cuartil de 'si' en gana_azul y el tercer cuartil de 'no' en gana_azul.

Por tanto, se aprecia gráficamente que la diferencia entre medias de diferencia de experiencia respecto a el ganador de la partida es real. 


## 5.3 Compración distribución de la variable kda en función de la posición

Se ha realizado un contraste de hipótesis entre más de dos grupos, concretamente se ha estudiado la diferencia de KDA entre las diferentes posiciones, pero solo para el equipo ganador de la partida. Y hemos encontrado que las distribuciones de los KDAS son diferentes en función de la posición del equipo ganador. Además que el orden de distribución mayor a menor es algo así: 
top<sup<=jng<=mid<adc

```{r,eval=TRUE,echo=TRUE}

# plot de densidad
todos_kdas %>% 
  ggplot(aes(x=kda, fill =posicion )) +
  geom_density(color="black", alpha=0.5, position = 'identity')

# boxplot
todos_kdas %>% 
  ggplot(aes(y=kda, x =posicion, fill=posicion)) +
  geom_boxplot(color="black", alpha=0.5, position = 'identity')
```

Esta vez se ha desarrollado un gráfico de densidad para comparar la distribución de KDA entre posición y el boxplot. 
En el gráfico de densidad podemos claramente ver como el pico de densidad mayor entre todas las distribuciones es de los ADC, seguido de los de JNG y MID , y seguidoS de los de SUP y TOP. 
En estos gráficos de densidad podemos ver que la principal diferencia entre MID y JNG es que los MID tienen una distribución con dos picos, de manera que los MID suelen tener un KDA entorno a 6-7 al ganar, pero también es bastante posible que ganen con un KDA de 10-12. Mientras que los JNG, no tienen este pico y su distribución de KDA es más normal. Esto es lo que hace que el KDA de los MID se parezca más a los de ADC. 
Además, vemos que la principal diferencia entre el KDA de los SUP frente a los TOP, es que el kda de los TOP es el que presenta un mayor pico entorno a 4-5 de KDA, mientras que los SUP también tienen el pico en estos valores, pero su distribución se aumenta más hacia valores mayores. 

Al ver los boxplot, vemos como aunque las distribuciones están solapadas en partes, el orden que habíamos propuesto se cumple, y la posición con mayor KDA por distribución es ADC, seguido de MID (que su mediana es inferior pero su tercer cuartil es casi igual que la de los ADC), seguido por JNG (que su mediana es inferior a MID aunque su primer cuartil es muy parecido), seguido por SUP (parecido a JNG pero con una distribución con más tendencia a valores pequeños) y por último TOP (con una distribución y mediana menor que el resto).

## 5.4 Curva ROC modelo de regresión para predecir que equipo gana (primera regresión)

Respecto al primer modelo de regresión que hemos generado, hemos visto que es muy bueno prediciendo si el equipo azul ganará  o perderá la partida (gana rojo). El problema que presenta es que no podemos estudiar los factores influyentes en la victoria o derrota porque los p-valores del modelo son todos de 1. 

Este modelo, hemos visto su matriz de confusión y su métricas de rendimiento, hemos visto que su acierto es muy alto igual que el resto de métricas. Otra métrica que se suele calcular es la AUC ROC. Esta métrica nos indica el rendimiento del modelo respecto al compromiso entre la tasa de verdaderos positivos y la tasa de falsos positivos, y se suele usar para medir la calidad del modelo. Siendo 1 el máximo valor y siendo 0.5 un acierto aleatorio. 

Calculo el AUC ROC y grafico la curva visualmente

```{r,eval=TRUE,echo=TRUE}


require(pROC)
require(cvAUC)

# se obtiene la prediccion
prob <- predict(glm_train,Test, type="response")

# Se obtiene un objeto de predicción que tiene información sobre los tp, tn, fp y fn. 
ROCRpred <- prediction(prob, Test$gana_azul)

# Se obtiene un objeto performance con el tpr y fpr
ROCRperf <- performance(ROCRpred, 'tpr', 'fpr')

# Se dibuja la curva roc
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2, 1.7))

# A partir del objeto prediction anterior, obtenemos la auc
auc <- performance(ROCRpred, measure = "auc")

auc <- auc@y.values[[1]]

print(paste0("El area bajo la curva ROC es de ", auc))

```

Vemos como el valor de la métrica es de 0.9845, un valor muy muy alto. Por lo tanto vemos que nuestro modelo es muy bueno. Además, observando la gráfica podemos ver que es casi perfecta también. 

Concluímos que este modelo, aunque no permita saber realmente porque se acierta en la predicción. Sí que permite acertar correctamente y esto lo vemos reflejado en todas sus métricas. 


## 5.5 Curva ROC modelo de regresión para predecir si un equipo gana (segunda regresión)

Nuestro segundo modelo de regresión logística se utiliza para predecir si un equipo gana o pierde la partida, solo en función de sus datos. 

En principio, hemos visto mediante la matriz de confusión y las métricas de acierto, que el modelo es un poco peor que el primer modelo. Eso sí, también tenemos la ventaja de que este modelo es interpretable. A continuación, calculo la AUC ROC y visualizo la curva ROC de este modelo. 

```{r,eval=TRUE,echo=TRUE}

prob <- predict(glm_train2,Test2, type="response")

# Se obtiene un objeto de predicción que tiene información sobre los tp, tn, fp y fn. 
ROCRpred <- prediction(prob, Test2$gana)

# Se obtiene un objeto performance con el tpr y fpr
ROCRperf <- performance(ROCRpred, 'tpr', 'fpr')

# Se dibuja la curva roc
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2, 1.7))

# A partir del objeto prediction anterior, obtenemos la auc
auc <- performance(ROCRpred, measure = "auc")

auc <- auc@y.values[[1]]

print(paste0("El area bajo la curva ROC es de ", auc))

```

Viendo la curva ROC, vemos que esta es incluso mejor que la anterior, puesto que se ve ligeramente más completa. Al estudiar la AUCROC, vemos que el valor es de 0.996, un punto mejor que el modelo de regresión anterior, y rozando la perfección.

Por tanto, este modelo, que además es interpretable, desde el punto de vista de AUC ROC es un mejor modelo que el modelo anterior. 


## 5.6 Odds ratio para la regresión para predecir si un equipo gana (segunda regresión)

Este segundo modelo de regresión, ya hemos comentado que es interpretable. 

Hemos visto, que las variables con más seguridad de influencia en el modelo son el número de torres, y el kda de jng, top y sup. Esto lo sabemos porque sus p-valores son inferiores a 0.05. 

Ahora, queremos estudiar para donde influyen las diferentes variables del modelo. Esto se hace mediante el odds ratio. Este odds ratio, nos indica el aumento de probabilidades por cada punto que se sube en la variable. De manera que un odds ratio de 2 para una variable x, indica que por cada punto de x que se aumenta, se multiplica las probabilidades de ganar por 2. 
El valor de un odds ratio puede estar entre 0 e infinitio, siendo 1 el valor que indica que las probabilidades de ganar la partida se multiplican por 1, es decir que son iguales.

Hay que destacar, que para las variables que han sido seleccionadas como factores importantes por su p-valor. El odds ratio es un valor significativamente diferente de 1, incluso en su intervalo de confianza. Para las variables que no han sido seleccionadas por su p-valor. Podemos destacar que su odds ratio puede ser diferente de 1, pero que por su intervalo de confianza no estamos significativamente seguros de su influencia en las probabilidades de ganar. Puede haber un odds raitio de 2, pero que su intervalo de confianza sea de 0.99 a 3.01. Y que aunque se vea que esta variable posiblemente influye en ganar la partida, no hay seguridad estadísticamente hablando. 

Grafico el odds ratio de las variables del modelo y posteriormente estudio su influencia.


```{r,eval=TRUE,echo=TRUE}

# grafico de los odds ratio
plot_model(glm_train2, show.values = TRUE, value.offset = .4, digits = 4,  title = "Odds ratio for step_model")


```

Al estudiar los odds ratio, vemos como las variables con un odds ratio mayor de 1, significa que aumentan las probabilidades de ganar por el valor del odds ratio. Y las que tienen un odds ratio menor de 1, que disminuyen las probabilidades de ganar.

Estudio los odds ratio 1 por 1:

* num_torres: Esta variable ha sido seleccionada como un factor importante para decidir la victoria, y vemos como su odds ratio es el mayor de todos y el más claro. Tiene un valor de 4.9, lo que significa que las probabilidades de ganar una partida se multiplican por 4.9 por cada torre conseguida por un equipo. Esto es lógico, puesto que como ya comentamos uno de los objetivos más importantes del juego es el número de torres, y vimos como las variables de torres tenían mucha correlación con la variable objetivo.   
* inhibs: Para esta variable, llama la atención que su valor es de 0.53, aunque al ver el intervalo de confianza, se observa que este incluso llega a superar a 1. Lo que en teoría puede ocurrir con esta variable, es que obtener un inhibidor es necesario para ganar, pero obtener muchos inhibidores, puede significar que aunque un equipo esta cerca de ganar, no consigue cerrar la partida, y por eso consigue y consigue más inhibidores. Por tanto, se da que no hay certeza clara que conseguir un inhibidor te aumente las probabilidades de ganar. Ya que quedarte con un inhibidor y ganar la partida es posible.    
* DamageObjectives: El daño a objetivos, es una variable con un rango muy grande, que además tiene mucha relación con num_torres, puesto que las torres son objetivos. Su odds ratio es 1.0009, lo que sifnifica que por cada punto de daño a objetivos, se multiplican las posibilidades de ganar por 1.0009, aunque parezca poco, hay que tener en cuenta el rango de esta variable y que pueden aumentarse en 1000 o 2000 puntos el daño a objetivos, lo que significaría un aumento grande en las posibilidades de ganar. Lamentablemente, el intervalo de confianza está incluso por debajo de 1, por lo que aunque la influencia de esta variable parece positiva para ganar, no tenemos seguridad estadística.   
* kda_mid: Vemos que el odds ratio de la variable es de 1.21, por lo que aparentemente influye positivamente en ganar la partida, el problema de esta variable es que su intervalo de confianza pasa por 1, y por tanto no hay seguridad estadística para asegurar que el kda del mid influye positivamente.   
* kda_jng: Vemos que es el kda con mayor odds ratio, y por tanto, el más influyente en la partida. Por cada punto de kda que consigue el jungla, se multiplican las probabilidades de ganar una partida por 1.57. Además es significativo, por lo que estamos seguros de su influencia positiva. 
* kda_sup: Vemos que es el segundo kda con mayor odds ratio. Por cada punto aumenta las posibilidades de ganar la partida en 1.42. Estamos seguros de su influencia porque es un factor importante.    
* kda_adc: Ocurre lo mismo que con el kda del jng y sup, pero esta vez el kda del adc solo multiplica las probabilidades de ganar la partida en 1.27. Aun así, es significativo.   
* kda_top: Es el kda menos influyente por odds ratio, y porque su intervalo de confianza está por debajo de 1, por lo que ni siquiera podemos tener seguridad estadística de su influencia positiva en ganar la partida. El valor del odds ratio es de 1.1980.   
* num_asesinatos: El odds ratio es menor de 1, concretamente de 0.9446, pero su intervalo de confianza está por encima de 1. Entiendo que el funcionamiento de esta variable es igual que el de inhibs. Aunque en teoría conseguir asesinatos es mejor para ganar, puede ser que si consigues muchos asesinatos, realmente solo sea porque no consigues acabar la partida ganando. Esto hace que el odds ratio tenga este intervalo de confianza cerca de uno, y que la variable tenga un odds ratio aparentemente que disminuye el ganar.    
* num_dragones: El odds ratio es de 1.2378, pero su intervalo de confianza hace que no sea significativo estadísticamente puesto que pasa por el 1. Eso sí, vemos como el odds ratio es positivo y conseguir un dragon multiplica las posibilidades de ganar. Esto es diferente que la variable inhibs o num_asesinatos, porque los dragones están diseñados para que cuando consigues 4 tienes una gran ventaja respecto al rival, lo que hace que merezca la pena siempre conseguir dragones, aunque su significancia no esté probada.     
* double_k: El odds ratio es de 1.6415, lo que es bastante alto solo superado por el num_torres, pero no tiene significancia estadística. Esta falta de significancia se puede deber a que el conseguir un doble asesinato, normalmente influye en que dominas al rival, pero puede ser que el rival consiga igual un doble asesinato en una pelea grupal y por tanto el doble asesinato realmente no aporte a la victoria. Igualmente, aunque no haya significancia estadística, el conseguir un asesinato doble multiplica las posibilidades de ganar por 1.6415.    
* oro_al_15, cura, diferencia_exp, y diff_oro_al_15: Todas estas variables tienen un odds ratio muy cercano a 1 o de 1, y su efecto en las probabilidades de ganar se parece al que hemos visto en damageObjectives pero con un odds ratio menor, es decir, con menos influencia en las probabilidades de ganar que el daño a objetivos. Se parece su odds ratio, porque todas estas variables también tienen un rango alto, y por tanto conseguir un punto en estas no es dificil, pero conseguir muchos puntos si que tiene que influir en la victoria.    


# 6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

Al principio del estudio, se planteaba resolver los siguientes problemas en base al dataset de partidas de League of Legends profesional: 

* Identificar las variables relacionadas con la victoria de un equipo.
* Describir las variables relacionadas con la victoria de un equipo.
* Identificar diferencias en variables relacionadas con la victoria de un equipo. 
* **Identificar como influyen los factores importantes en la victoria.** 
* **Identificar que equipo va a ganar una partida.**

Se ha conseguido resolver todos estos problemas en base a los análisis estadísticos del estudio realizados en el punto 4 y graficados en el 5. **Las conclusiones que permiten responder estos problemas son:**

1. **Se ha conseguido identificar una lista de 30 variables más importantes de todo el dataset reducido frente a la variable objetivo gana.** Las variables relacionadas con la victoria de un equipo son aquellas variables con una correlación de Spearman de 0.5 o más con la variable gana. **Estas variables han sido el número de torres, el daño a objetivos, los inhibidores, el KDA de los jugadores, los asesinatos, los dragones, los nashors, los dobles asesinatos, el oro al minuto 15, la curación realizada, la diferencia de oro al minuto 15 y la diferencia de experiencia al minuto 15.**  
2. Mediante un análisis estadístico descriptivo se han descrito las variables relacionadas con la victoria de un equipo. Se ha estudiado su normalidad, su homocedasticidad respecto a los grupos de ganar, su rango y su distribución. De esta manera **hemos podido comprender los entresijos de las variables y hacernos una idea de los posibles análisis estadísticos inferenciales y predictivos.** 
3. **Se ha identificado que no hay diferencias en la probabilidad de ganar una partida solo por ser lado azul o lado rojo.** Lo cual demuestra que en principio, el lado azul y el rojo tienen que ser mejores en la partida para ganar, identificando que los equipos influyen en la victoria. 
4. Se ha estudiado que el daño a objetivos por parte del equipo azul cuando gana respecto a cuando pierde es significativamente mayor. Identificando una diferencia clara en una variable relacionada con la victoria. **Indicando que conseguir más daño a objetivos es algo a lo que aspira el equipo azul para ganar.** 
5. **Se ha concluido que la diferencia de experiencia cuando un equipo gana es diferente a cuando pierde, y por tanto, entendiendo junto con los gráficos del punto 5, que el equipo azul tiene que buscar aumentar la diferencia de experiencia para ganar la partida.** Esto es otra diferencia encontrada en las variables relacionadas con la victoria de un equipo.
6. He identificado que hay una diferencia de KDA entre los diferentes jugadores del equipo que gana. Y he visto que el orden de KDA de menor a mayor es: top<sup<=jng<=mid<adc. **Lo que nos lleva a concluir, que un equipo debería de tener como adc al jugador que más es capaz de sobrevivir, y como top al jugador que más sabe como sacrificarse por el equipo.**
7. Se ha desarrollado un modelo predictivo de regresión logística que permite acertar el 97.6% de partidas en el conjunto de test, **lo que significa que hemos desarrollado un muy buen modelo predictivo para identificar el ganador entre dos equipos.**
8. Se ha desarrollado otro modelo predictivo, que nos permite conocer si un equipo va a ganar o perder la partida, solo observando sus datos, con un acierto del 96.88% pero con una AUCROC casi perfecta. Lo interesante de este modelo es que es interpretable. 
9. Gracias al modelo para identificar si un equipo va a ganar la partida, **hemos concluido que los factores más influyentes en la victoria de un equipo son el número de torres que derriban y el kda de su jng, sup y adc.**
10. Gracias al modelo para identificar si un equipo va a ganar la partida y estudiar sus odds ratio, **he identificado como influyen estos factores en la victoria, viendo que cada torre conseguida multiplica las posibilidades de conseguir una victoria por más de 4 puntos, y viendo que conviene que el jng tenga un buen kda antes que las otras posiciones, o viendo que hay variables como inhibs o num_asesinatos que por su funcionamiento influyen negativamente en aumentar las posibilidades de victoria.**

Con las conclusiones vemos que estas preguntas se han respuesto con las siguientes conclusiones:

* Identificar las variables relacionadas con la victoria de un equipo: 1.  
* Describir las variables relacionadas con la victoria de un equipo: 2.  
* Identificar diferencias en variables relacionadas con la victoria de un equipo: 3,4,5,6.  
* **Identificar como influyen los factores importantes en la victoria: 7,8.**  
* **Identificar que equipo va a ganar una partida: 9.10.** 

# Apendices: 

## Apendice 1. Guardar datos finales analizados.

Según el guión de la práctica he de generar ficheros para los datasets finales analizados. Por tanto, guardo el dataset que se ha utilizado para los análisis estadísticos, el cual tiene las 31 variables utilizadas. 
Además, guardo los datasets que se han ido generando derivados de este, ya sea los datasets de partidas que gana el azul o el rojo, el dataset de kdas de jugadores que su equipo gana y el dataset de partidas formateado para generar la segunda regresión logística.

```{r,eval=TRUE,echo=TRUE}

# guardo los datasets
write.csv2(lol_imputed_onehot, '../Data/Output/lol_professional_games_final.csv', sep=',',row.names = FALSE)
write.csv2(equipos, '../Data/Output/lol_professional_games_separated_teams.csv', sep=',',row.names = FALSE)
write.csv2(gana, '../Data/Output/lol_professional_games_bluewins.csv', sep=',',row.names = FALSE)
write.csv2(pierde, '../Data/Output/lol_professional_games_redwins.csv', sep=',',row.names = FALSE)
write.csv2(todos_kdas, '../Data/Output/lol_professional_games_kdaofwinnerplayers.csv', sep=',',row.names = FALSE)


```

## Apendice 2. Tabla de contribuciones.

```{r,eval=TRUE,echo=TRUE}

# genero la tabla de contribuciones
data.frame(Contribuciones =c("Investigación previa", "Redacción de las respuestas", "Desarrollo código"), Firma = c("Manuel Ruiz Botella", "Manuel Ruiz Botella","Manuel Ruiz Botella")) %>% kable() %>% kable_styling()


```