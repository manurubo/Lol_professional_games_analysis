---
title: "Codigo_reducido"
author: "ManuelRuizBotella"
date: "December 25, 2020"
output:
  pdf_document: default
  html_document: default
mainfont : TimesNewRoman
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE,}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
require(dplyr)
require(kableExtra)
require(VIM)
require(mltools)
require(data.table)
require(ggplot2)

```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# 1. Descripción del dataset.

(AÑADIR DESCRIPCION INICIAL)

```{r,eval=TRUE,echo=TRUE}
# Tenemos que tener el fichero en el mismo directorio que el codigo.
fichero <- paste(getwd(),'Lol_ProfessionalGames.csv', sep='/')
fichero
lol <- read.csv2(fichero,sep=',')
lol_base<- lol

# Comprobar que los datos se han cargado en el dataframe correctamente
str(lol)

# Comprobar que las dimensiones del dataframe son correctas, 614 filasx517columnas
dim(lol)

# Comprobar los tipos de las variables
sapply(lol,class)


```

# 2. Selección de los datos. 

Como tenemos muchas variables, tenemos que eliminar aquellas que nos vayamos a usar o que no sean muy importantes o supongan información que se recoge en otras variables. 

## Variables no necesarias.

De primeras, podemos eliminar la fecha, parche, nombre de equipos, nombre de jugadores o campeones o los summoners utilizados. Aunque estos aspectos son importantes para ganar, como por ejemplo jugar un campeón agresivo o defensivo, los eliminamos del conjunto de datos puesto que son factores difíciles de analizar en un análisis estadístico debido a la cantidad de factores que tiene. 

Antes de eliminar el equipo hay que cambiar el valor de las variables primera_sangre y primera_torre, para identificar si la obtuvo el equipo rojo o el azul.


```{r,eval=TRUE,echo=TRUE}


lol$primera_sangre <- as.factor(ifelse(as.character(lol$primera_sangre) == as.character(lol$nombre_azul), 'azul','rojo'))
lol$primera_torre <- as.factor(ifelse(as.character(lol$primera_torre) == as.character(lol$nombre_azul), 'azul','rojo'))

eliminar <- c('torneo','parte', 'fecha','semana', 'parche','nombre_rojo','nombre_azul', 'top_azul', 'jng_azul','mid_azul','adc_azul','sup_azul','top_rojo', 'jng_rojo','mid_rojo','adc_rojo','sup_rojo')

lol<-lol %>% select(-(all_of(eliminar))) 
lol<-lol %>% select(-(contains("ban")| contains("pick")| contains("summoner")))

head(lol) %>% select(c("primera_sangre", "primera_torre"))
```

## Variables duplicadas 

Además, en el dataset hay información duplicada respecto a algunas variables, como por ejemplo el oro o los subditos asesinados. Es importante mencionar que siempre que se puede, se intenta trabajar con el valor de la variable por minuto, puesto que no sirve de nada si un equipo consigue mucho oro pero simplemente es porque pierde la partida y esta partida es muy larga. 

A continuación voy seleccionando los datos que me interesan del dataset respecto a diferentes aspectos de la partida, para reducir el dataset y obtener los mismos datos solo de una manera.

### Creeps (Subditos)

Para los subditos, tenemos la variable CSM_posición_equipo que queremos mantener, ya que representa los subditos por minuto, el resto de variables respecto a los subditos se eliminan. Por una parte css_posicion_equipo es la misma información sin tener encuenta el tiempo. Por otra parte, las variables cs_in_jung_team y cs_in_jung_enemy, son variables muy específicas, que actualmente no vamos a usar en los análisis y que se encuentran ya sus valores dentro de la variable CSM_posicion_equipo. 
Respecto a las variables de CSD.15_equipo_posicion, que representan la diferencia de cs al minuto 15 para cada posición de los equipos, no la selecciono, porque la diferencia de cs en media partida, aunque es importante, está incluida en los CS por minuto. 

```{r,eval=TRUE,echo=TRUE}


lol<-lol %>% select(-(contains("css_")| contains("cs_in_jung")| contains("CSD.15")))
head(lol) %>% select(contains("CSM"))
```

### Asesinatos, Muertes y Asistencias. 

La información de asesinatos, muertes y asistencias se puede condensar en una métrica que se suele utilizar en el juego, que es el KDA, este KDA se compone por (Asesinatos+Asistencias)/Muertes, de tal manera que generamos un KDA para cada jugador de la partida, condensando la información de Kills, Deaths y Assists de cada jugador en una variable. 

Por otra parte, aunque el desempeño de un jugador es muy importante de estudiar para ver si el equipo gana o pierde, ya que puede ser que solo un jugador haga que un equipo gane, en estos análisis nos vamos a centrar más en estudios respecto al desempeño del equipo, mirando solo en pocas variables clave el desempeño de los jugadores. Es por esto, que mientras que conservamos los KDA para cada jugador, la información de solokills, doblekills, triplekills, cuadrakills y pentakills, las vamos a agrupar en una por equipo. 

```{r,eval=TRUE,echo=TRUE}

lol$kda_top_azul <- (lol$kills_top_azul+lol$assists_top_azul)/lol$deaths_top_azul
lol$kda_jng_azul <- (lol$kills_jng_azul+lol$assists_jng_azul)/lol$deaths_jng_azul
lol$kda_mid_azul <- (lol$kills_mid_azul+lol$assists_mid_azul)/lol$deaths_mid_azul
lol$kda_adc_azul <- (lol$kills_adc_azul+lol$assists_adc_azul)/lol$deaths_adc_azul
lol$kda_sup_azul <- (lol$kills_sup_azul+lol$assists_sup_azul)/lol$deaths_sup_azul

lol$kda_top_rojo <- (lol$kills_top_rojo+lol$assists_top_rojo)/lol$deaths_top_rojo
lol$kda_jng_rojo <- (lol$kills_jng_rojo+lol$assists_jng_rojo)/lol$deaths_jng_rojo
lol$kda_mid_rojo <- (lol$kills_mid_rojo+lol$assists_mid_rojo)/lol$deaths_mid_rojo
lol$kda_adc_rojo <- (lol$kills_adc_rojo+lol$assists_adc_rojo)/lol$deaths_adc_rojo
lol$kda_sup_rojo <- (lol$kills_sup_rojo+lol$assists_sup_rojo)/lol$deaths_sup_rojo

lol$solo_k_azul <- lol %>% select(contains("Solo_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$double_k_azul <- lol %>% select(contains("Double_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$triple_k_azul <- lol %>% select(contains("Triple_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$quadra_k_azul <- lol %>% select(contains("Quadra_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$penta_k_azul <- lol %>% select(contains("Penta_kills_azul"))%>% rowSums(na.rm = TRUE)
lol$solo_k_rojo <- lol %>% select(contains("Solo_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$double_k_rojo <- lol %>% select(contains("Double_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$triple_k_rojo <- lol %>% select(contains("Triple_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$quadra_k_rojo <- lol %>% select(contains("Quadra_kills_rojo"))%>% rowSums(na.rm = TRUE)
lol$penta_k_rojo <- lol %>% select(contains("Penta_kills_rojo"))%>% rowSums(na.rm = TRUE)


lol<-lol %>% select(-(contains("kills")| contains("deaths")| contains("assists")))
head(lol) %>% select(contains("kda")| contains("_k_"))

```

### Oro.

El oro es la estadística más importante del juego. Los asesinatos, los subditos, las torres, los monstruos de la jungla, todos los objetivos del juego cuando se consiguen te otorgan oro, por tanto, está claro que un equipo que gana en la gran mayoría de partidas, tiene más oro que el equipo perdedor. 
Lo demuestro para eliminar la variable que se refiere al oro final del dataset.

```{r,eval=TRUE,echo=TRUE}

lol$gana <- as.factor(ifelse(lol$gana_azul == 1, 'azul','rojo'))

require(stringr)
lol$num_oro_azul <- as.integer(str_replace(lol$num_oro_azul,'k',''))*1000
lol$num_oro_rojo <- as.integer(str_replace(lol$num_oro_rojo,'k',''))*1000
lol$mas_oro <- as.factor(ifelse(lol$num_oro_azul == lol$num_oro_rojo, 'iguales', ifelse(lol$num_oro_azul > lol$num_oro_rojo, 'mas_azul','mas_rojo') ))

table(lol$mas_oro,lol$gana)

eliminar2 <- c('num_oro_azul','num_oro_rojo', 'mas_oro','gana_azul', 'gana_rojo')

lol<-lol %>% select(-(all_of(eliminar2))) 

```

Se observa perfectamente que es cierto, y que posiblemente los pocos casos donde el equipo con menos oro gana, es una partida muy igualada. Por tanto, como hacer una correlación o un modelo de regresión con la variable de oro al final de la partida sería un poco trampa, puesto que ya sabemos que hay una gran correlación entre el oro y ganar la partida, la metodología típica para analizar el oro de los equipos se suele medir por el oro en el minuto 15 de los equipos. En este minuto, las partidas no están decididas, pero si podemos ver si hay un equipo que ha dominado claramente los primeros minutos de la partida. Por tanto, vamos a trabajar con el oro del equipo en el minuto 15, y con la diferencia de oro en estos minutos. 

El oro de cada jugador no lo vamos a usar, porque aunque sea muy util, realmente este oro se consigue con los objetivos que ya se ven representados en el dataset, asique no hace falta tener información de oro por cada jugador. Por tanto eliminamos todas las variables ya sean temporales o de final de partida, que hacen referencia al oro.
Eso sí, vamos a usar la variable GPM_equipo_posicion para detectar cual fue el jugador con más oro por equipo y nos quedamos con esta posición como jugador más valioso del equipo. Generado una nueva variable. 


```{r,eval=TRUE,echo=TRUE}

oro_azul<-str_split(lol$oro_azul, ',')
lol$oro_al_15_azul<-unlist(lapply(oro_azul, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

oro_rojo<-str_split(lol$oro_rojo, ',')
lol$oro_al_15_rojo<-unlist(lapply(oro_rojo, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

# la diferencia será positiva si es para el azul o negativa para el rojo
diferencia_oro<-str_split(lol$diferencia_oro_azul, ',')
lol$diff_oro_al_15<-unlist(lapply(diferencia_oro, function(x) as.integer(str_replace(unlist(x)[3], " '15 min': ",''))))

lol<-lol %>% mutate(MasValioso_azul = case_when(
    (GPM_azul_top >= GPM_azul_jng) & (GPM_azul_top >= GPM_azul_mid) & (GPM_azul_top >= GPM_azul_adc) & (GPM_azul_top >= GPM_azul_sup) ~ "top",
    (GPM_azul_jng >= GPM_azul_top) & (GPM_azul_jng >= GPM_azul_mid) & (GPM_azul_jng >= GPM_azul_adc) & (GPM_azul_jng >= GPM_azul_sup) ~ "jng",
    (GPM_azul_mid >= GPM_azul_top) & (GPM_azul_mid >= GPM_azul_jng) & (GPM_azul_mid >= GPM_azul_adc) & (GPM_azul_mid >= GPM_azul_sup) ~ "mid",
    (GPM_azul_adc >= GPM_azul_top) & (GPM_azul_adc >= GPM_azul_jng) & (GPM_azul_adc >= GPM_azul_mid) & (GPM_azul_adc >= GPM_azul_sup) ~ "adc",
    TRUE ~ 'sup'
  )
)
lol<-lol %>% mutate(MasValioso_rojo = case_when(
    (GPM_rojo_top >= GPM_rojo_jng) & (GPM_rojo_top >= GPM_rojo_mid) & (GPM_rojo_top >= GPM_rojo_adc) & (GPM_rojo_top >= GPM_rojo_sup) ~ "top",
    (GPM_rojo_jng >= GPM_rojo_top) & (GPM_rojo_jng >= GPM_rojo_mid) & (GPM_rojo_jng >= GPM_rojo_adc) & (GPM_rojo_jng >= GPM_rojo_sup) ~ "jng",
    (GPM_rojo_mid >= GPM_rojo_top) & (GPM_rojo_mid >= GPM_rojo_jng) & (GPM_rojo_mid >= GPM_rojo_adc) & (GPM_rojo_mid >= GPM_rojo_sup) ~ "mid",
    (GPM_rojo_adc >= GPM_rojo_top) & (GPM_rojo_adc >= GPM_rojo_jng) & (GPM_rojo_adc >= GPM_rojo_mid) & (GPM_rojo_adc >= GPM_rojo_sup) ~ "adc",
    TRUE ~ 'sup'
  )
)
  


eliminar3 <- c('oro_azul','oro_rojo', 'diferencia_oro_azul','diferencia_oro_rojo')

lol<-lol %>% select(-(all_of(eliminar3)))
lol<-lol %>% select(-(contains("Golds")| contains("GPM")| contains("gold")))
head(lol) %>% select(c("oro_al_15_azul", "oro_al_15_rojo", "diff_oro_al_15", "MasValioso_azul", "MasValioso_rojo"))

```

### Vision

En el juego se consigue visión el mapa gracias a la visión, está claro que cuanto más tiempo pasa, más wards se colocan en el mapa y se destruyen, por tanto las variables tienen que estar estandarizadas por el tiempo de la partida. 

Debido a que se pueden poner wards normales o de control de visión, además que es importante no solo poner los wards sino eliminarlos, se creó la métrica Vision Score o VS. Esta métrica representa una puntuación que recoje wards colocados, eliminados y la calidad de la visión que otorgan los wards. Por tanto, en el estudio vamos a usar solo la puntuación de Vision Score, eliminando el resto de variables. Además, aunque puede ser útil saber el desempeño de cada jugador en la visión del equipo, debido a que no vamos a realizar grandes análisis sobre la visión en el trabajo, agrupamos la vision score por equipos, generando una vision score para el equipo azul y otra para el rojo. 

```{r,eval=TRUE,echo=TRUE}

fecha <- str_split(lol$tiempo,':')
lol$tiempo<-unlist(lapply(fecha, function(x) as.integer(unlist(x)[1])))

lol<-lol %>% mutate(ScoreVision_azul = (Vision_Score_azul_top + Vision_Score_azul_jng + Vision_Score_azul_mid + Vision_Score_azul_adc + Vision_Score_azul_sup)/tiempo)
lol<-lol %>% mutate(ScoreVision_rojo = (Vision_Score_rojo_top + Vision_Score_rojo_jng + Vision_Score_rojo_mid + Vision_Score_rojo_adc + Vision_Score_rojo_sup)/tiempo)

lol<-lol %>% select(-(contains("Wards")| contains("Vision_Score")| contains("VS")))
head(lol) %>% select(contains("ScoreVision"))




```

### Daño

Respecto al daño tenemos muchas variables. Tenemos información sobre el daño total realizado y de que tipo de daño es, el daño recibido, el daño realizado a objetivos, el daño a campeones enemigos, el daño por minuto a enemigos, el porcentaje de daño por persona en cada equipo, el daño a torres, etc. 

De nuevo, aunque es importante el daño por cada jugador, es obvio que eso son muchas variables y por tanto, la única variable que vamos a mantener por jugador es la de daño por minuto (DPM). Como este daño es daño a campeones, podemos eliminar las variables que hacen referencia a daño a campeones total y porcentaje de daño. La información de daño mágico, físico o verdadero a campeones que tenemos por jugador, la condensamos en equipo y la dividimos por minuto, para saber la cantidad de cada tipo a campeones.
Además, el daño realizado a objetivos se combina por equipos y se divide por minuto. Respecto al daño total y daño recibido,se eliminan las variables porque el daño total no es tan importante, sino que nos centramos en el daño en campeones y objetivos y porque el daño recibido por un equipo es inverso al daño realizado por el otro y si ya tenemos los daños realizados por equipo no tiene sentido tener el recibido. 

Por último, el daño a torres se recoge obviamente en el número de torres eliminadas, por tanto se puede eliminar la variable. 

```{r,eval=TRUE,echo=TRUE}




lol<-lol %>% mutate(PhysicalDamageChampions_azul = (Physical_Damage_Champions_azul_top + Physical_Damage_Champions_azul_jng + Physical_Damage_Champions_azul_mid + Physical_Damage_Champions_azul_adc + Physical_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(PhysicalDamageChampions_rojo = (Physical_Damage_Champions_rojo_top + Physical_Damage_Champions_rojo_jng + Physical_Damage_Champions_rojo_mid + Physical_Damage_Champions_rojo_adc + Physical_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(MagicDamageChampions_azul = (Magic_Damage_Champions_azul_top + Magic_Damage_Champions_azul_jng + Magic_Damage_Champions_azul_mid + Magic_Damage_Champions_azul_adc + Magic_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(MagicDamageChampions_rojo = (Magic_Damage_Champions_rojo_top + Magic_Damage_Champions_rojo_jng + Magic_Damage_Champions_rojo_mid + Magic_Damage_Champions_rojo_adc + Magic_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(TrueDamageChampions_azul = (True_Damage_Champions_azul_top + True_Damage_Champions_azul_jng + True_Damage_Champions_azul_mid + True_Damage_Champions_azul_adc + True_Damage_Champions_azul_sup)/tiempo)
lol<-lol %>% mutate(TrueDamageChampions_rojo = (True_Damage_Champions_rojo_top + True_Damage_Champions_rojo_jng + True_Damage_Champions_rojo_mid + True_Damage_Champions_rojo_adc + True_Damage_Champions_rojo_sup)/tiempo)
lol<-lol %>% mutate(DamageObjectives_azul = (Total_Damage_Objectives_azul_top + Total_Damage_Objectives_azul_jng + Total_Damage_Objectives_azul_mid + Total_Damage_Objectives_azul_adc + Total_Damage_Objectives_azul_sup)/tiempo)
lol<-lol %>% mutate(DamageObjectives_rojo = (Total_Damage_Objectives_rojo_top + Total_Damage_Objectives_rojo_jng + Total_Damage_Objectives_rojo_mid + Total_Damage_Objectives_rojo_adc + Total_Damage_Objectives_rojo_sup)/tiempo)

lol<-lol %>% select(-(contains("Damage_Dealt")| contains("Damage_Objectives")| contains("Damage_Taken")| contains("Damage_Champions")| contains("DMG")| contains("Damage_towers")| contains("damage_Champios")))
head(lol) %>% select(contains("DPM") | contains( "Damage"))



```

### Experiencia y niveles

Para la información de experiencia y niveles en el juego, ocurre como con el oro, que evidentemente cuando un equipo gana la partida, tiene más nivel y experiencia que el contrario. Por tanto, se trabaja con las variables al minuto 15. Concretamente tenemos la diferencia de experiencia y niveles. Mantenemos ambas variables porque mientras que tener un nivel de ventaja puede suponer mucho en el minuto 15, realmente no sabemos si esto es porque se tiene una pequeña ventaja y justo al 15 había un jugador superior al otro, o porque la diferencia entre jugadores es muy grande realmente. 
Como trabajamos con diferencia de experiencia entre cada jugador de cada posición para los equipos, tendremos solo una variable, que será positiva si la ventaja la tiene el equipo azul y negativa si la tiene el rojo. 

```{r,eval=TRUE,echo=TRUE}

lol<-lol %>% mutate(diferencia_exp = XPD.15_azul_top + XPD.15_azul_jng + XPD.15_azul_mid + XPD.15_azul_adc + XPD.15_azul_sup)
lol<-lol %>% mutate(diferencia_nivel = LVLD.15_azul_top + LVLD.15_azul_jng + LVLD.15_azul_mid + LVLD.15_azul_adc + LVLD.15_azul_sup)

lol<-lol %>% select(-(contains("XPD.15")| contains("LVLD.15")))
head(lol) %>% select(contains("exp")| contains( "nivel"))


```

### Curaciones y control de campeones.

Las curaciones se pueden realizar en el juego por diversas maneras, ya sean robo de vida, campeones que curan o con pociones. Por tanto se mantiene la variable pero se agrupa y convierte a curación por minuto. 
El control de campeones es vital en muchas partidas, consiste en el tiempo que un campeon enemigo es inmovilizado o ralentizado por un campeon. Igual que las curaciones, agrupamos por equipo y se convierte a cc por minuto. 

```{r,eval=TRUE,echo=TRUE}

lol<-lol %>% mutate(cura_azul = (heal_azul_top + heal_azul_jng + heal_azul_mid + heal_azul_adc + heal_azul_sup)/tiempo)
lol<-lol %>% mutate(cura_rojo = (heal_rojo_top + heal_rojo_jng + heal_rojo_mid + heal_rojo_adc + heal_rojo_sup)/tiempo)
lol<-lol %>% mutate(cc_azul = (ccing_azul_top + ccing_azul_jng + ccing_azul_mid + ccing_azul_adc + ccing_azul_sup)/tiempo)
lol<-lol %>% mutate(cc_rojo = (ccing_rojo_top + ccing_rojo_jng + ccing_rojo_mid + ccing_rojo_adc + ccing_rojo_sup)/tiempo)

lol<-lol %>% select(-(contains("ccing")| contains("heal")))
head(lol) %>% select(contains("cura") | contains( "cc"))


```


### Porcentaje de jungla.

Las variables jng_share_15 y jng_share, representan el porcentaje de monstruos de la jungla que ha tenido un equipo respecto al otro. Evidentemente, ambas variables son complementarias para cada equipo, por lo que podemos quedarnos solo con una, que sea el extra de porcentaje de jungla que ha tenido el equipo azul respecto al rojo. Si el valor es positivo es que el azul ha matado más monstruos de la jungla y si es negativo es el rojo el equipo que ha matado más monstruos de la jungla. 

```{r,eval=TRUE,echo=TRUE}


lol<-lol %>% mutate(ventaja_jung_15 = as.numeric(as.character(jng_share_15_azul)) - as.numeric(as.character(jng_share_15_rojo)))
lol<-lol %>% mutate(ventaja_jung = as.numeric(as.character(jng_share_azul)) - as.numeric(as.character(jng_share_rojo)))

lol<-lol %>% select(-(contains("share")))
head(lol) %>% select(contains("ventaja"))


```



# 3. Limpieza de los datos

Como primer paso de la limpieza de los datos, tenemos que mirar el tipo de los diferentes atributos del dataset.
```{r,eval=TRUE,echo=TRUE}

sapply(lol, class) 

```

Vemos que todas las variables tienen el tipo correcto salvo las de subditos por minuto (CSM). Por tanto, hemos de corregir su tipo a numeric. 
También falla el tipo de las variables MasValiosoAzul y MasValiosoRojo, que aparecen como character y tienen que ser factores. 

```{r,eval=TRUE,echo=TRUE}


lol$CSM_azul_top <- as.numeric(as.character(lol$CSM_azul_top))
lol$CSM_azul_jng <- as.numeric(as.character(lol$CSM_azul_jng))
lol$CSM_azul_mid <- as.numeric(as.character(lol$CSM_azul_mid))
lol$CSM_azul_adc <- as.numeric(as.character(lol$CSM_azul_adc))
lol$CSM_azul_sup <- as.numeric(as.character(lol$CSM_azul_sup))
lol$CSM_rojo_top <- as.numeric(as.character(lol$CSM_rojo_top))
lol$CSM_rojo_jng <- as.numeric(as.character(lol$CSM_rojo_jng))
lol$CSM_rojo_mid <- as.numeric(as.character(lol$CSM_rojo_mid))
lol$CSM_rojo_adc <- as.numeric(as.character(lol$CSM_rojo_adc))
lol$CSM_rojo_sup <- as.numeric(as.character(lol$CSM_rojo_sup))

lol$MasValioso_azul<- as.factor(lol$MasValioso_azul)
lol$MasValioso_rojo<- as.factor(lol$MasValioso_rojo)


```

A continuación muestro las dimensiones del dataset y el str, sin limpiar.

```{r,eval=TRUE,echo=TRUE}

# Comprobar que los datos se han cargado en el dataframe correctamente
str(lol) 

# Comprobar que las dimensiones del dataframe son correctas, 614 filasx517columnas
dim(lol)

```

## 3.1 Datos vacíos. 

Vamos a estudiar si el conjunto de datos presenta elementos vacíos o ceros. En caso de que haya una variable igual a 0, esto puede ser porque el valor es realmente 0 o porque es un elemento perdido, igual que los elementos vacíos. Estos elementos vacíos por tanto, pueden aparacer como 0, NA o como un valor indicativo de que falta el valor como '-'. 

En caso de que un valor sea 0 tenemos que identificar su causa. Para todos aquellos elementos vacíos tendremos que decidir como solucionar la falta de información. Por una parte, se puede eliminar la instancia, suponiendo una perdida de datos. Otra solución es dejar claro que falta ese dato con una etiqueta como por ejemplo 'Desconocido', esta solución puede ser efectiva sobre todo para las variables que son un factor. Una solución algo más interesante es sustituir el valor por una medida de tendencia central como la media o mediana en las variables numéricas, o la clase más utilizada en las variables categóricas. Por último, se pueden imputar estos valores vacíos en función de los valores del conjunto de datos mediante métodos probabilistas. Esta última solución suele ser la mejor porque el valor no es el mismo para todas las instancias que se encuentran vacías. 

Compruebo si los datos tienen elementos iguales a 0 o elementos vacíos:



```{r,eval=TRUE,echo=TRUE}

# Compruebo los elementos que son 0
sapply(lol, function(x) sum(x==0, na.rm=T))

```


Vemos que hay muchas variables con 0, pero tenemos que tener en cuenta que en todas estas variables es algo normal. Es muy posible que los asesinatos de un equipo o otro sean 0, lo mismo puede ocurrir con torres, dragones, nashors, heraldos, inhibidores, rachas de asesinatos o asesinatos en solitario. Todo esto ocurre porque un equipo puede ir muy mal y no conseguir asesinatos o objetivos, lo cual hace que su valor sea 0. 
Otras variables con 0 son la diferencia de nivel, y la ventaja en la jungla, las cuáles es posible también que sean 0 porque no haya diferencias entre ambos equipos. 
Las últimas variables a comentar que es lógico que tengan 0 son los kda de los jugadores, de nuevo, esto se explica porque un jugador ha muerto varias veces y no ha asesinado ni ayudado en nada. Se da en pocas ocasiones, pero en partidas a gran nivel es posible, ya que muchas veces un equipo es capaz de dominar toda la partida sin dar opciones al rival. 
Por último, se observa un 0 en CSM_rojo_sup, esto se puede deber a que un jugador no asesinó ningún súbdito en la partida, aunque extraño, es posible y sobretodo en los support, se puede estar jugando algún support muy defensivo (como puede ser una soraka o yuumi) que no haya asesinado ningún súbdito.

Para estudiar porque puede ocurrir el valor de 0 en CSM_rojo_sup, accedemos al dataset lol_base y busco el campeón jugado para ver si es cierta mi suposición. 

```{r,eval=TRUE,echo=TRUE}

as.character(lol_base[which(lol_base$CSM_rojo_sup=='0'),]$pick5_rojo)
```

Efectivamente, vemos que el campeón que consiguió 0 de CSM era Yuumi, este campeón se caracteriza por que se sube a un compañero suyo y no ataca, sino que se dedica a protegerle, por lo que es bastante aceptable que tuviera 0 subditos en la partida. 

Por tanto, mantenemos todos los 0 en el conjunto de datos, puesto que todos parecen ser valores lógicos y correctos. 

A continuación estudio los valores vacíos del dataset. 

```{r,eval=TRUE,echo=TRUE}

sapply(lol, function(x) sum(is.na(x) | x==''))

```

Vemos que hay varias variables con valores vacíos. Para todas estas variables podemos considerar que se debe a errores en el web scraping o que faltaba la información en la propia web. Por tanto, habrá que solucionar estos valores vacíos para las variables que hacen referencia a heraldos, inhibidores, oro al 15, puntuación de visión, daño a objetivos, diferencia de nivel o experiencia, valores de curación o de cc, o FirstBlood. 

Eso sí quiero estudiar porque se produce el NA en las variables de kda de los jugadores, puesto que es un campo calculado por nosotros y es posible que haya un problema en el cálculo. Para esto miro en lol_base, los asesinatos, muertes y asistencias de aquellos jugadores que tienen NA en su kda. Para simplificarlo todo, solo miro los de kda_adc_rojo que es el que más NA tiene. 


```{r,eval=TRUE,echo=TRUE}

lol_base[which(is.na(lol$kda_adc_rojo)),]$kills_adc_rojo
lol_base[which(is.na(lol$kda_adc_rojo)),]$deaths_adc_rojo
lol_base[which(is.na(lol$kda_adc_rojo)),]$assists_adc_rojo
```

Vemos que estos jugadores, no asesinaron, ni asistieron, ni fueron asesinados en la partida, por lo que el cálculo de su KDA es 0+0/0 que es NA, por tanto, realmente este valor de las variables KDA que es NA, tiene que ser sustituido por el valor 0. 

Para el resto de variables tenemos que imputar los NA. Lo realizo mediante el método de kNN. Este método se basa en la similitud entre diferentes atributos del dataset, de manera que se puede estimar el valor de un atributo vacío en funcion de los atributos más parecidos a este. 

```{r,eval=TRUE,echo=TRUE}



lol$kda_top_azul <- ifelse(is.na(lol$kda_top_azul), 0, lol$kda_top_azul)
lol$kda_jng_azul <- ifelse(is.na(lol$kda_jng_azul), 0, lol$kda_jng_azul)
lol$kda_mid_azul <- ifelse(is.na(lol$kda_mid_azul), 0, lol$kda_mid_azul)
lol$kda_adc_azul <- ifelse(is.na(lol$kda_adc_azul), 0, lol$kda_adc_azul)
lol$kda_sup_azul <- ifelse(is.na(lol$kda_sup_azul), 0, lol$kda_sup_azul)

lol$kda_top_rojo <- ifelse(is.na(lol$kda_top_rojo), 0, lol$kda_top_rojo)
lol$kda_jng_rojo <- ifelse(is.na(lol$kda_jng_rojo), 0, lol$kda_jng_rojo)
lol$kda_mid_rojo <- ifelse(is.na(lol$kda_mid_rojo), 0, lol$kda_mid_rojo)
lol$kda_adc_rojo <- ifelse(is.na(lol$kda_adc_rojo), 0, lol$kda_adc_rojo)
lol$kda_sup_rojo <- ifelse(is.na(lol$kda_sup_rojo), 0, lol$kda_sup_rojo)

lol$First_Blood<-ifelse(lol$First_Blood=='',NA, as.character(lol$First_Blood))

# Consigo el nombre de las variables con nulos
nulls<-as.data.frame(sapply(lol, function(x) sum(is.na(x))))
colnames(nulls) <- 'nulls'
nulls$index <-rownames(nulls)
vars_with_nulls<-nulls[which(nulls$nulls!=0),]$index


lol_imputed<-kNN(lol, k=3)

# muestro que se han corregido los nulos. 
sapply(lol_imputed[vars_with_nulls], function(x) sum(is.na(x)))

lol_imputed$First_Blood <- as.factor(as.character(lol_imputed$First_Blood))


```

## 3.2 Valores extremos. 

Los valores extremos son datos que se encuentran tan alejados de los valores normales de una variable que hacen sospechar si estos valores son realmente válidos o si por el contrario se deben a un error en la recolección de los datos. En caso de observar que realmente los errores no son erróneos aunque si extremos, se pueden mantener los valores. Si se detectan que los valores extremos son debido a problemas y erróneos, entonces se tienen que corregir, ya sea mediante una transformación lógica (quizás se tengan que cambiar decimales) o mediante una imputación de los valores como si de valores vacíos se trataran.

Es importante destacar que los valores extremos, obviamente solo se pueden obtener para aquellas variables que son numéricas.

Primero vamos a estudiar los valores extremos para detectarlos:

```{r,eval=TRUE,echo=TRUE}

lol_numericas <- lol_imputed %>% select(where(is.numeric) | where(is.integer))

sapply(lol_numericas, function(x) boxplot.stats(x)$out)



```

Se observa que hay una gran cantidad de variables que tienen valores extremos, eso sí, vemos que todos los outliers tienen más o menos sentido en las distribuciones de los datos. Es decir, que aunque en el boxplot se detecta un outlier, este es simplemente un candidato a valor extremo, pero al compararlo con los datos en los boxplots, vemos que realmente este valor es un valor real válido, y que aparece como un outlier por simple distribución de los datos. Es normal, que haya alguna partida que un jugador sobresalga y se haga una cantidad de subditos por minuto alta pero POSIBLE, o que un equipo juegue una composición de curar y por tanto su valor de cura sea muy alto pero POSIBLE, o que se detecten 6 inhibidores como un valor extremo porque normalmente un equipo puede ganar uno o dos pero los inhibidores pueden reaparecer a los 5 minutos con lo que el enemigo tienen que volver a destruirlo. 

Vemos como se le puede identificar una lógica a la posible aparación de los outliers en los datos para casi todas las variables, una importante de mencionar es el valor de Infinito para las variables de KDA que se produce cuando un jugador no ha muerto en la partida pero al menos ha conseguido una asistencia o asesinato. Para estas variables podríamos dejar el valor Inf puesto que no está mal, es cierto, pero se puede optar por simplemente volver a los datos iniciales (lol_base) y recalcular el KDA teniendo en cuenta que si las muertes de un jugador son 0, se sustituye el valor por 1. De tal manera que si un jugador asesinó 5 veces, asistió en 2 asesinatos y no murió su KDA será 7 en vez de Infinito. Así podemos distinguir cuando un jugador domina mucho la partida matando mucho y no muere, que podría tener un KDA de 25, y un jugador que no domina pero tampoco muere y podría tener un KDA de 3. Sin hacer esto ambos tendrían Infinito. 

```{r,eval=TRUE,echo=TRUE}

lol2<-lol_base

lista<-c('deaths_top_azul','deaths_jng_azul','deaths_mid_azul','deaths_adc_azul','deaths_sup_azul','deaths_top_rojo','deaths_jng_rojo','deaths_mid_rojo','deaths_adc_rojo','deaths_sup_rojo')
lol2[lista]<-as.data.frame(sapply(lol2[lista], function(x) ifelse(x==0,1,x)))

lol2$kda_top_azul <- (lol2$kills_top_azul+lol2$assists_top_azul)/lol2$deaths_top_azul
lol2$kda_jng_azul <- (lol2$kills_jng_azul+lol2$assists_jng_azul)/lol2$deaths_jng_azul
lol2$kda_mid_azul <- (lol2$kills_mid_azul+lol2$assists_mid_azul)/lol2$deaths_mid_azul
lol2$kda_adc_azul <- (lol2$kills_adc_azul+lol2$assists_adc_azul)/lol2$deaths_adc_azul
lol2$kda_sup_azul <- (lol2$kills_sup_azul+lol2$assists_sup_azul)/lol2$deaths_sup_azul

lol2$kda_top_rojo <- (lol2$kills_top_rojo+lol2$assists_top_rojo)/lol2$deaths_top_rojo
lol2$kda_jng_rojo <- (lol2$kills_jng_rojo+lol2$assists_jng_rojo)/lol2$deaths_jng_rojo
lol2$kda_mid_rojo <- (lol2$kills_mid_rojo+lol2$assists_mid_rojo)/lol2$deaths_mid_rojo
lol2$kda_adc_rojo <- (lol2$kills_adc_rojo+lol2$assists_adc_rojo)/lol2$deaths_adc_rojo
lol2$kda_sup_rojo <- (lol2$kills_sup_rojo+lol2$assists_sup_rojo)/lol2$deaths_sup_rojo

# tengo los kda bien calculados en lol2
lista_kda<-c('kda_top_azul','kda_jng_azul','kda_mid_azul','kda_adc_azul','kda_sup_azul','kda_top_rojo','kda_jng_rojo','kda_mid_rojo','kda_adc_rojo','kda_sup_rojo')

lol2<-lol2 %>% select(all_of(lista_kda))
lista_kda_2 <- paste("2",lista_kda, sep='_')
colnames(lol2) <- lista_kda_2

lol[lista_kda_2]<- lol2


lol$kda_top_azul <- ifelse(lol$kda_top_azul == Inf, lol$`2_kda_top_azul`, lol$kda_top_azul)
lol$kda_jng_azul <- ifelse(lol$kda_jng_azul == Inf, lol$`2_kda_jng_azul`, lol$kda_jng_azul)
lol$kda_mid_azul <- ifelse(lol$kda_mid_azul == Inf, lol$`2_kda_mid_azul`, lol$kda_mid_azul)
lol$kda_adc_azul <- ifelse(lol$kda_adc_azul == Inf, lol$`2_kda_adc_azul`, lol$kda_adc_azul)
lol$kda_sup_azul <- ifelse(lol$kda_sup_azul == Inf, lol$`2_kda_sup_azul`, lol$kda_sup_azul)

lol$kda_top_rojo <- ifelse(lol$kda_top_rojo == Inf, lol$`2_kda_top_rojo`, lol$kda_top_rojo)
lol$kda_jng_rojo <- ifelse(lol$kda_jng_rojo == Inf, lol$`2_kda_jng_rojo`, lol$kda_jng_rojo)
lol$kda_mid_rojo <- ifelse(lol$kda_mid_rojo == Inf, lol$`2_kda_mid_rojo`, lol$kda_mid_rojo)
lol$kda_adc_rojo <- ifelse(lol$kda_adc_rojo == Inf, lol$`2_kda_adc_rojo`, lol$kda_adc_rojo)
lol$kda_sup_rojo <- ifelse(lol$kda_sup_rojo == Inf, lol$`2_kda_sup_rojo`, lol$kda_sup_rojo)

lol<-lol %>% select(-all_of(lista_kda_2))

#repito la imputación realizada antes para tener los datos bien
lol_imputed<-kNN(lol, k=3)

# muestro que se han corregido los nulos. (como ya se producia antes)
sapply(lol_imputed[vars_with_nulls], function(x) sum(is.na(x)))

# muestro que en las imputadas ya no hay estos problemas con las variables de KDA
sapply(lol_imputed[lista_kda], function(x) boxplot.stats(x)$out)

lol_imputed$First_Blood <- as.factor(as.character(lol_imputed$First_Blood))

```



# 4. Análisis de los datos.

Los análisis de datos son una parte imprescindible en este trabajo, debido a que al realizarlos podemos extraer conocimiento de los datos que tenemos en nuestro dataset.
El proceso de analizar los datos no se puede dividir en fases concretas, ya que muchas veces el realizar un análisis o otro depende de los análisis ya realizados y el conocimiento extraído. Por tanto, yo voy a seguir los títulos que se siguen en la práctica, pero de manera que por ejemplo, para la selección de datos voy a utilizar una aplicación de prueba estadística. Los análisis de datos a realizar por tanto son:

* Análisis de correlación de las variables con la variable objetivo 'gana'. Este análisis estadístico lo realizo en la fase de selección para selección un dataset reducido que usar más adelante. 
* Aplicación de un análisis estadístico descriptivo de las variables. 
* Realización de un contraste de probabilidades.
* Realización de un contraste de hipótesis entre dos grupos, que se definirá posteriormente entre que variables en función de las variables seleccionadas y el estudio de la normalidad y la homocedasticidad. 
* Realización de un contraste de hipótesis entre más de dos grupos.
* Desarrollo de un modelo de regresión logística para predecir el ganador de una partida. 

## 4.1 Selección de los grupos de datos que se quieren analizar/comparar.

Para realizar la selección de los grupos de datos que se quieren analizar, podemos hacerlo de diferentes maneras, en definitiva lo importante es seleccionar el conjunto de datos que sea útil para realizar los análisis. En este caso, todavía tenemos muchos datos por cada instancia, así que lo interesante es reducir el conjunto de datos por una reducción de dimensionalidad. 

Por una parte, esto se puede hacer mediante algoritmos como PCA, que aplica una reducción de las dimensiones seleccionando m nuevas variables no correlacionadas entre ellas a partir de las variables del dataset. 
En nuestro caso, para aprovechar la realización de un análisis estadístico, vamos a detectar las variables más correlacionadas con la variable objetivo 'gana'. Seleccionaremos aquellas variables más correlacionadas. De manera que en esta selección hacemos una reducción de la dimensionalidad por la correlación. 

Para tener todas las variables numéricas y poder hacer la correlación de Pearson, hemos de hacer un OneHotEncoding de las variables categóricas. Primero muestro cuales son binarias y cuales son nominales 

```{r,eval=TRUE,echo=TRUE}

lol_imputed<-lol_imputed[,1:ncol(lol)]

vars_2_niveles<-sapply(lol_imputed,function(x) length(levels(x))==2)
vars_2_niveles<-names(vars_2_niveles[which(vars_2_niveles==TRUE)])
print("Las variables binarias son: " )
print(vars_2_niveles)

vars_mas_niveles<-sapply(lol_imputed,function(x) length(levels(x))>2)
vars_mas_niveles<-names(vars_mas_niveles[which(vars_mas_niveles==TRUE)])
print("Las variables nominales son: " )
print(vars_mas_niveles)

```

Por tanto, las variables binarias podemos aplicarles un OneHotEncoding sin ningún problema, nos quedaremos solo con una de las categorías sin problema. Por tanto, nos quedaremos con la primera_sangre_azul, la primera_torre_azul y nuestra variable objetivo será gana_azul. De manera que en todas estas variables un 1, será el equipo azul y un 0 el equipo rojo. 

Para las variables nominales hay varias posibilidades, podemos mantenerlas como nominales y calcular su coeficiente de correlación respecto a gana_azul mediante un análisis ANOVA, obteniendo el coeficiente de correlación como la raíz cuadrada del eta cuadrado. Otra posibilidad es simplemente aplicar OneHotEncoding a las variables, de manera que cada categoría de la variable será una variable nueva y estudiaremos su correlación con la variable gana. 


```{r,eval=TRUE,echo=TRUE}

lol_imputed_onehot <- as.data.frame(one_hot(as.data.table(lol_imputed)))
lol_imputed_onehot$gana_rojo<-NULL
lol_imputed_onehot$primera_sangre_rojo<-NULL
lol_imputed_onehot$primera_torre_rojo<-NULL

dim(lol_imputed_onehot)

```

Vemos que por el OneHotEncoding, ahora tenemos 104 variables debido a que hay 3 variables que se han dividido en varias variables. Esto no supone ningún problema porque vamos a aplicar la correlación sobre todas las variables y reducir el dataset a las más correlacionadas. 

```{r,eval=TRUE,echo=TRUE}

variables_a_correlacion<-c(colnames(lol_imputed_onehot %>% select(-'gana_azul')))

correlaciones<-as.data.frame(sapply(lol_imputed_onehot[variables_a_correlacion], function(x) cor(x,lol_imputed_onehot$gana_azul)))

colnames(correlaciones)<-'correlacion'

correlaciones$correlacion_abs<-abs(correlaciones$correlacion)

correlaciones<-correlaciones[order(-correlaciones$correlacion_abs),]
correlaciones_importantes<-correlaciones[which(correlaciones$correlacion_abs>0.5),]
correlaciones_importantes %>% kable()

```

Vemos que al sacar el valor absoluto de las correlaciones, podemos ordenarlas para sacar aquellas variables que más correlacion tienen con la variable objetivo gana. Al seleccionar las variables, definimos el límite de correlación en 0.5 absoluto. 
Las 26 variables que tienen una correlación mayor de 0.5 absoluto, y por tanto utilizaremos en nuestro estudio analítico son:

* El número de torres para los dos equipos. 
* El daño a objetivos para los dos equipos. 
* El número de inhibidores para los dos equipos. 
* El KDA para cada uno de los jugadores de la partida. 
* El número de asesinatos de cada equipo. 
* El número de dragones totales para cada equipo. 
* El número de nashors para cada equipo. 
* El número de dobles asesinatos realizados por el equipo rojo. 
* El oro al minuto 15 para el equipo rojo. 
* La diferencia de oro al minuto 15. 
* La diferencia de experiencia al minuto 15. 

Es importante destacar que, que todas las variables seleccionadas son individuales o si tienen una pareja han aparecido ambas en la selección, salvo la variable oro_al_15_rojo, que no tiene su pareja oro_al_15_azul y la variable double_k_rojo que no tiene su pareja double_k_azul. Por tanto las añado manualmente aunque no sobrepasen el límite de selección de correlación. 

```{r,eval=TRUE,echo=TRUE}

correlaciones[which(rownames(correlaciones)=='oro_al_15_azul'),]

correlaciones[which(rownames(correlaciones)=='double_k_azul'),]

```

Vemos que la variable de asesinatos dobles del equipo azul se ha quedado muy cerca de pasar el límite, lo cual es normal si los asesinatos dobles del equipo rojo lo han pasado. Pero se observa que la correlación de oro_al_15_azul es muy baja, de 0.38. De igual manera, las añado puesto que son dos variables y le otorgan una "lógica" al dataset. 

Por último, si miramos las correlaciones vemos que las correlaciones de las variables derivadas de first_blood, MasValiosoAzul y MasValiosoRojo son muy bajas y están lejos del límite, por tanto está claro que pertenecer a una categoría de estas variables no es útil para determinar que equipo gano en la partida. 

```{r,eval=TRUE,echo=TRUE}
require(tibble)
correlaciones<-rownames_to_column(correlaciones, var = "variable") 
correlaciones %>% filter(grepl('MasValioso|First_Blood', `variable`) )

```

Ariiba observamos que la correlación absoluta mayor es de 0.11 y por tanto estas variables aportarían muy poco. 

Por si acaso, y para asegurarnos de que aunque cada categoría de las variables no tiene una gran correlación, si usáramos la variable por si misma tampoco tendría correlación mayor de 0.5, vamos a obtener la correlación mediante un análisis ANOVA para estas variables frente a la variable gana_azul. 

```{r,eval=TRUE,echo=TRUE}

library(heplots) # for eta
model.aov <- aov(lol_imputed_onehot$gana_azul ~ lol_imputed$First_Blood)
summary(model.aov)

paste0("El coeficiente de correlación de FirstBlood sería: ",sqrt(etasq(model.aov, partial = FALSE)[1,1]))

library(heplots) # for eta
model.aov <- aov(lol_imputed_onehot$gana_azul ~ lol_imputed$MasValioso_rojo)
summary(model.aov)

paste0("El coeficiente de correlación de MasValioso_rojo sería: ",sqrt(etasq(model.aov, partial = FALSE)[1,1]))

library(heplots) # for eta
model.aov <- aov(lol_imputed_onehot$gana_azul ~ lol_imputed$MasValioso_azul)
summary(model.aov)

paste0("El coeficiente de correlación de MasValioso_azul sería: ",sqrt(etasq(model.aov, partial = FALSE)[1,1]))

```

Vemos que sin duda, la correlación de First_Blood por sí sola es superior a la de sus categorías por separado. De igual manera, su correlación es la mitad del límite, por tanto podemos olvidarnos de esta variable y mantener las 26 variables seleccionadas por el límite más las dos que vamos a añadir por ser pareja de alguna variable seleccionada. Las otras variables siguen teniendo correlaciones muy bajas. 

```{r,eval=TRUE,echo=TRUE}

variables_importantes<-rownames(correlaciones_importantes)
variables_importantes<-c(variables_importantes, 'oro_al_15_azul', 'double_k_azul', 'gana_azul')

lol_imputed_onehot<-lol_imputed_onehot[variables_importantes]

dim(lol_imputed_onehot)
```

Vemos que el dataset se ha reducido a 29 variables, que son las 28 variables seleccionadas por correlación más la variable objetivo. 

## 4.2 Comprobación de la normalidad y homogeneidad de la varianza.

Para poder realizar un contraste de hipótesis, ya sea una comparación entre dos grupos o entre más grupos, es necesario comparar la normalidad y homocedasticidad de las variables. 
En caso de que las variables sean normales y tengan homogeneidad de la varianza, se pueden aplicar test paramétricos como la t de Student o ANOVA. Sino, se tendrán que aplicar test no paramétricos como Wilcoxon o Mann-Whitney o Kruskal-Wallis. 

Respecto a la comprobación de normalidad y homocedasticidad, yo voy a realizarlo todo en el conjunto de datos que tenemos actualmente. Pero si queremos realizar un nuevo análisis de una variable aquí no presente, tendremos que comprobar su normalidad, y en caso de que queramos realizar un contraste de hipótesis de una variable presente pero utilizando una variable categórica eliminada para separar en grupos, como por ejemplo el equipo o la liga, tendremos que comprobar la homocedasticidad en función de esta variable categórica.

### 4.2.1 Comprobación de la normalidad

Primero compruebo la normalidad de las variables numéricas. Esta claro que la variable objetivo gana_azul no se tiene que estudiar su normalidad puesto que es una variable binaria. 
La normalidad de las variables se comprueba mediante el test de Saphiro-Wilk, su hipótesis nula es que la variable se encuentra distribuída normalmente, por tanto, si su p-valor es menor a 0.05 es que la variable no se encuentra distribuída normalmente. 

De igual manera, por el teorema del límite central a partir de una muestra de más de 30, se puede considerar que la distribución es normal aunque los test como Saphiro-Wilk digan que no. 

```{r,eval=TRUE,echo=TRUE}

lol_imputed_onehot$gana_azul<-as.factor(ifelse(lol_imputed_onehot$gana_azul == 1, 'si','no'))
lol_imputed_onehot$gana_azul <- factor(lol_imputed_onehot$gana_azul, levels=c("si", "no") )

lol_numericas <- lol_imputed_onehot %>% select(where(is.numeric) | where(is.integer))

pvalores<-sapply(lol_numericas, function(x) shapiro.test(x)$p.value)

print("Las variables con distribución normal y sus p-valores son:")
pvalores[which(pvalores>=0.05)]

normales<-names(pvalores[which(pvalores>=0.05)])

print("Las variables sin distribución normal y sus p-valores son:")
pvalores[which(pvalores<0.05)]

nonormales<-names(pvalores[which(pvalores<0.05)])
```

Vemos que las unicas variables con distribución normal son la diferencia de oro en el minuto 15 y la diferencia de experiencia en el minuto 15. Las otras variables están muy lejos de tener una distribución normal al ver sus p-valores. 
Esto lo tendremos en cuenta al hacer contraste de hipótesis.

### 4.2.2 Comprobación de la homocedasticidad.

Partiendo de la normalidad, hay dos maneras de comprobar la homocedasticidad de las variables. Si la variable sigue una distribución normal, la varianza se ha comprobar por el Levene Test, mientras que si la variable no sigue no distribución normal se ha de comprobar la homocedasticidad por el Fligner Test. 
En ambos test, la hipótesis nula asume homocedasticidad de las varianzas, por lo que si el p-valor es de menos de 0.05 se rechaza la hipótesis nula y hay heterocedasticidad de las varianzas. 

Es importante mencionar, que yo voy a obtener la homocedasticidad para las variables numéricas frente a la variable objetivo gana_azul. 

```{r,eval=TRUE,echo=TRUE}


pvalores<-sapply(lol_numericas[normales], function(x) leveneTest(x ~ lol_imputed_onehot$gana_azul)$`Pr(>F)`[1])

print("Las variables con distribución normal, tienen todas homocedasticidad porque sus p-valores son:")
pvalores[which(pvalores>=0.05)]

normales_homocedasticidad<-names(pvalores[which(pvalores>=0.05)])

pvalores<-sapply(lol_numericas[nonormales], function(x) fligner.test(x ~ lol_imputed_onehot$gana_azul)$p.value)

print("Las variables sin distribución normal, que no tienen homocedasticidad y sus p-valores son:")
pvalores[which(pvalores<0.05)]

nonormales_heterocedasticidad<-names(pvalores[which(pvalores<0.05)])

print("Las variables sin distribución normal, que tienen homocedasticidad y sus p-valores son:")
pvalores[which(pvalores>=0.05)]

nonormales_heterocedasticidad<-names(pvalores[which(pvalores>=0.05)])

```


Por tanto, podemos concluir que las 2 únicas variables con distribución normal, además tienen homocedasticidad debido a que sus p-valores son superiores 0.05, son la diferencia de oro al 15 y la diferencia de experiencia al 15.

Por otra parte, el resto de variables no tienen una distribución normal, pero hay un pequeño grupo de variables que si que tiene varianzas iguales para los diferentes grupos en función de la variable objetivo, estas son el daño a objetivos por parte del equipo rojo y azul, el número de torres del equipo rojo y el oro al 15 del equipo azul. El resto de variables presentan heterocedasticidad. 

## 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos.

Hay que recordar que la primera prueba estadística ya la hemos realizado en la selección de atributos con el objetivo de reducir la dimensionalidad mediante la identificación de la correlación de las diferentes variables con la variable objetivo. 

Las pruebas a realizar son: 
* Análisis estadístico descriptivo.
* Contraste de proporción de victoria del azul es superior al rojo.
* Contraste de que el daño a objetivos por parte del equipo azul es superior cuando gana a cuando pierde.
* Contraste de si la diferencia de experiencia en el minuto 15 es igual independientemente de si gana o pierde el equipo azul. 
* Contraste de diferencia de KDA entre posiciones para el equipo ganador.


### 4.3.1 Análisis estadístico descriptivo. 

Antes de realizar análisis estadísticos más profundos para determinar características del dataset, es importante realizar un análisis descriptivo que nos permita identificar aspectos importantes del conjunto de datos. Dentro de este análisis descriptivo se podría incluir el estudio de normalidad y varianza ya realizado hasta ahora. Por tanto, me voy a rescindir a estudiar el sumario del conjunto de datos y representaré las variables en gráficas. **A pesar de que las gráficas deberían de pertenecer al ejercicio 5, es lógico que para estudiar el análisis descriptivo del conjunto de datos representemos un histograma de las variables, por tanto desarrollo los histogramas de las variables en este apartado.**

Para realizar este análisis y no abrumarnos, vamos a ir comparando las variables en función de su ámbito.

#### 4.3.1.1 Descripción de las objetivos, daño a objetivos, y ganar

Debido a que la variable gana_azul es la variable objetivo la introduzco en el análisis de los objetivos. Además así la podemos tener presente en todos los análisis para describir comportamientos. 

```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}

# Plot del histograma
plot_hist<-function(x)
{
  print(ggplot(data=lol_imputed_onehot, aes(x=unlist(lol_imputed_onehot[x]))) +
  geom_histogram(
                 col="red",
                 fill="green",
                 alpha = .2) +
  labs(title=paste0("Histograma de ",x)) +
  labs(x=x, y="Frecuencia"))
}

vars <- c('num_torres_azul', 'num_torres_rojo', 'DamageObjectives_azul','DamageObjectives_rojo','inhibs_azul','inhibs_rojo', 'gana_azul')

summary(lol_imputed_onehot[vars])


gana_azul_porcentaje<-nrow(lol_imputed_onehot[which(lol_imputed_onehot$gana_azul=='si'), ])/nrow(lol_imputed_onehot)
paste0("El equipo azul gana un ", round(gana_azul_porcentaje,3), " y el rojo un ", 1-round(gana_azul_porcentaje,3))

invisible(sapply(vars[1:(length(vars)-1)],plot_hist))



```

Lo primero que llama la atención es que el equipo azul gana considerablemente más que el equipo rojo. 
Esto puede ser pura coincidencia o puede ser debido a que el equipo del lado azul tenga una ventaja. Generalmente, en el juego se prefiere jugar como el equipo azul, debido a que selecciona el primer campeón de la partida y que tiene un mejor acceso al lugar donde está el nashor. Sin embargo el rojo tiene el último campeón y mejor acceso al lugar del dragón.  

Respecto al resto de variables: 

1. Respecto a las variables de torres:
* Coinciden en el máximo y en el mínimo, esto es porque hay partidas donde un equipo no destruye torres y otras partidas donde un equipo destruye todas las torres (11). 
* Vemos como tanto en los cuartiles como en la media y mediana se observa que los valores de torres del equipo azul son superiores a los del rojo. Esto puede ser derivado por la ventaja que hemos visto que tiene el equipo azul, ya que sabemos que las variables tienen alta correlación con la variable objetivo, y por tanto, cuanto más torres destruye el equipo azul, más posibilidades de ganar la partida. 
* Además, al estudiar los histogramas vemos que la distribución de las torres es una distribución bimodal, donde se ve claramente que un equipo consigue normalmente muchas torres o muy pocas, pero un valor torres intermedio no suele ocurrir. Esto se debe a que un equipo gana y consigue muchas torres o pierde y consigue pocas torres. Es dificil que ambos equipos consigan un mismo numero de torres. 

2. Respecto a la variable de daño a objetivos:
* Se observa igual que en torres que los valores de tendencia central son superiores en el equipo azul, lo que posiblemente se debe a que el equipo azul gana más. 
* En el estudio de los histogramas de nuevo vemos que ambas variables de daño a objetivos son bimodales. Hay dos "montañas" en la distribución, lo normal es que en la variable de daño a objetivos azul, sea mayor cuando el equipo azul gane y menor cuando el equipo rojo (al contrario en la variable daño a objetivos rojo), lo que hace que se generen estas dos montañas. 
* Podemos hacer un contraste de hipótesis donde comprobemos si la media de daño a objetivos azul es la misma cuando gana el equipo azul o el rojo y posiblemente vemos como la media cuando gane cae en la montaña derecha y la media cuando pierde el azul cae en la montaña izquierda. 

3. Respecto a las variables de inhibidores destruidos por el equipo: 
* La diferencia entre equipo azul y rojo en el sumario se aprecia menos, aun así es interesante comentar como la mediana de inhibidores del rojo es 0, es decir que en más de la mitad de partidas ni consiguen un inhibidor, algo que es indispensable para ganar. Por otra parte la mediana del equipo azul si es 1. Como aspecto interesante, vemos como el máximo de inhibidores del rojo es 6 mientras que el del equipo azul es 5. Esto se puede deber a que el equipo azul gana antes de que sea necesario volver a destruir los 3 inhibidores. 
* La variable es numérica, no categórica, aunque vemos que solo pueden ser enteros y los valores en el dataset para las variables son pocos de 0 a 6 (o 5). En el histograma por tanto, podemos definir que la distribución de la variable es exponencial, ya que las primeras categorias tienen mucha mas posibilidad de ocurrir que las últimas. Esto se debe a que el equipo que gana mínimo tiene que destruir un inhibidor para ganar, pero no es necesario más, por lo que incluso cuando se ganan partidas, se puede ganar con un solo inhibidor.




#### 4.3.1.2 Descripción de los KDA


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}



vars <- c('kda_top_azul', 'kda_jng_azul', 'kda_mid_azul','kda_adc_azul','kda_sup_azul','kda_top_rojo', 'kda_jng_rojo', 'kda_mid_rojo','kda_adc_rojo','kda_sup_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

Para los KDA podemos comentar: 


* Al ver el sumario, pdoemos ver que según la posición hay un KDA mayor o menor, es decir que el KDA del top azul o rojo son más o menos parecidos, igual que el KDA de los junglas, de los medios, de los adc o de los support. Vemos por tanto, que de media, los jugadores con peor KDA son el top, seguido del support. En medio se encuentra el jungla, y los mejores KDA los tienen los medios, y sobretodo los ADC.
* Por otra parte, al estudiar los histogramas, vemos que todos tienen la misma distribución, aparentemente una distribución lognormal, donde el valor que más aparece está muy cerca al límite inferior (que es 0), pero que la distribución se extiende mucho a valores muy superiores que esta moda (cada vez con menor posibilidad de aparación). Es decir, que lo normal es que el KDA de un jugador sea entre 1 y 2, pero que el valor de este KDA puede superar de 10 o 15 sin problema. 



#### 4.3.1.3 Descripción de los asesinatos


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}


vars <- c('num_asesinatos_azul', 'num_asesinatos_rojo', 'double_k_azul','double_k_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al estudiar los asesinatos por equipos podemos ver:

* El número de asesinatos por equipo parece ser similar entre ambos equipos. Los valores son similares, vemos que ambos equipos de mediana tienen 12 asesinatos, y aunque el equipo azul tiene una media superior apenas se diferencian, por lo que parece que independientemente de la partida y su ganador, ambos equipos consiguen varios asesinatos. Eso sí, está claro que hay partidas donde algún equipo consigue 0 asesinatos, porque a veces un equipo es muy superior al otro. 
* Al ver el histograma, podemos ver como la distribución es positiva asimétrica, donde no se puede asegurar una forma concreta con nombre, Vemos de nuevo que los asesinatos suelen ser un valor entre 5 y 20, para ambos equipos y que pocas veces se obtienen menos o más asesinatos. 
* En comparación con las variables de daño a objetivos o torres, al ver esta distribución y no una distribución bimodal, vemos que no es tan claro que conseguir asesinatos repercute tan claramente como conseguir torres o objetivos en el resultado de la partida. En la distribución bimodal queda claro que normalmente caes en una montaña o en otra y en función de eso pierdes o ganas, en esta distribución puedes ganar una partida habiendo obtenido pocos asesinatos. 

2. Al estudiar las dobles kill por equipos podemos ver: 

* La variable es parecida a los inhibidores. Al mirar los histogramas es casi una variable categórica, aunque claramente es numérica porque se pueden conseguir infinitos dobles asesinatos en una partida. La distribución por tanto es exponencial, donde es muy posible que no se consigan 0 asesinatos dobles, y aumentar en 1 el valor de asesinatos dobles es menos probable. 
* Al ver el sumario vemos que ambas variables para el equipo azul y el rojo son muy parecidas, con misma mediana y medias muy similares. Ocurre por tanto como con asesinatos, que aunque como ya sabemos que su correlación es positiva para el azul y negativa para el rojo, y que por tanto se consiguen más asesinatos cuando se gana, puede ser que más dobles asesinatos no signifique nada para ganar. 




#### 4.3.1.4 Descripción de los monstruos de la jungla


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}


vars <- c('num_dragones_azul', 'num_dragones_rojo', 'num_nashors_azul','num_nashors_rojo')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al ver los dragones de ambos equipos podemos ver que:

* Al contrario que la mayoría de variables, en caso de los dragones la media es superior en el lado rojo. Esto se debe principalmente a algo que ya comentamos antes, y es que el lado rojo tiene ventaja en el lado del dragón. Por lo demás sus valores son parecidos.
* Al observar los histogramas, vemos de nuevo que aunque las variables son numéricas tienen un rango de valores bastante corto. En general destaca que la mayoría de partidas los equipos tienen entre 0 y 4 dragones y es muy dificil que pasen de esta cifra, esto se debe a que a partir de que un equipo tiene 4 dragones, obtiene una ventaja muy grande que hace que las partidas acaben pronto. 

2. Al ver los nashor de ambos equipos podemos ver que: 
* En este caso, vemos que la media de nashor es superior en el equipo azul, por su mayor capacidad de ganar y por su ventaja. Además vemos que incluso su tercer cuartil en ambos equipos es 1, mientras que la máxima son 4 y 3. Es decir, que normalmente un equipo consigue 0 o 1 nashor por partida, pero que se puede llegar a obtener muchos nashors, esto será normalmente en partidas igualadas. 
* Al ver el histograma, de nuevo vemos lo comentado, que normalmente un equipo tiene 0 o 1 nashors y es muy dificil obtener más. 




#### 4.3.1.3 Descripción del oro y experiencia


```{r,eval=TRUE,echo=TRUE, fig.height=3, fig.width=8}

colnames(lol_imputed_onehot)

vars <- c('oro_al_15_azul', 'oro_al_15_rojo', 'diff_oro_al_15','diferencia_exp')

summary(lol_imputed_onehot[vars])

invisible(sapply(vars,plot_hist))

```

1. Al comprobar el oro al minuto 15 de ambos equipos:

* En el sumario podemos comprobar como normalmente la ventaja en media y mediana la tiene el equipo azul, derivado posiblemente de que el equipo azul gana más partidas.
* Por otra parte vemos como el rango entre el mínimo y el máximo son unos 10000 de oro. Por lo tanto es muy importante conseguir cuanto más oro mejor, porque el valor superior es un 50% más del valor mínimo. 
* Al ver los histogramas, vemos como a pesar de que el test de saphiro-wilk dió que las variables no son normales, su distribución es bastante normal, y solo está un poco movida al mínimo. 

2. Al comprobar la diferencia de oro al minuto 15:
* Vemos como el valor mínimo y máximo son parecidos, lo que indica que el peor equipo rojo y el peor equipo azul han sido parecidos. Lo más importante es ver como el equipo azul normalmente tiene ventaja en esta variable puesto que la mediana y la media son positivas, y esto indica que el equipo azul tiene ventaja. 
* La distribución es normal, se aprecia totalmente en el histograma. 

### 4.3.2 Contraste de hipótesis

A continuación realizo varias pruebas de contraste de hipótesis: 

#### 4.3.2.1 Contraste de proporción de victoria del azul es superior al rojo

```{r,eval=TRUE,echo=TRUE}

# esto para contraste de hipotesis, usa lo de bernouilly de estadistica avanzada
prop.test( table(lol_imputed_onehot$gana_azul), conf.level=0.95, alternative = 'greater')

```

#### 4.3.2.2 Comprobación de que el daño a objetivos por parte del equipo azul es superior cuando gana a cuando pierde. 

Ya hemos realizado las pruebas de normalidad y de homocedasticidad. Para esta variable, ya hemos comprobado que su distribución no es normal (mediante la prueba de Saphiro-Wilk), sino que al estudiar su histograma hemos visto que la distribución es bimodal. Por otra parte, hemos visto mediante el test de fligner que su varianza en función del grupo de gana_azul es igual entre los grupos. 

Por tanto, ahora podemos aplicar el test no paramétrico Wilcoxon y comprobar si la distribución de daño a objetivos por parte del equipo azul en función del grupo es la misma o no. Además, como la distribución de varianza es la misma, si la distribución de un grupo es mayor, su mediana será mayor. 

Las hipotesis se fundamentan en estudiar si la posibilidad de que un elemento de una población sea mayor que un elemento de otra población. En caso de que tengamos dos poblaciones iguales, la probabilidad para ambas poblaciones será de 0.5. Por tanto, nosotros queremos comprobar si las posibilidades de que el daño a objetivos por parte del equipo azul cuando gana sean mayores que cuando pierde, o que sean iguales estas posibilidades.

$H_{0} : P(x_{i} > y_{i}) = 0.5$    
$H_{1} : P(x_{i} > y_{i}) > 0.5$ 

```{r,eval=TRUE,echo=TRUE}

gana<-lol_imputed_onehot[which(lol_imputed_onehot$gana_azul == 'si'),]
pierde<-lol_imputed_onehot[which(lol_imputed_onehot$gana_azul == 'no'),]

wilcox.test(gana$DamageObjectives_azul, pierde$DamageObjectives_azul, alternative = "greater", mu = 0,
            paired = FALSE, conf.int = 0.95)

```

Como vemos, el p-valor es muy muy pequeño, por lo que se rechaza la hipótesis nula y se acepta la hipótesis alternativa. Por tanto, las posibilidades de que el daño a objetivos por parte del equipo azul cuando gana son mayores que cuando pierde. Algo que en realidad, ya sospechabamos al ver la correlación entre las variables. Ahora hemos comprobado que hay significancia estadística. 

Esto lo comprobamos más adelante en el apartado 5, al observar la distribución de la variable en función de los grupos que se generan por gana_azul y al ver que las medianas son diferentes. 

#### 4.3.2.3 Comprobación de si la diferencia de experiencia en el minuto 15 es igual independientemente de si gana o pierde el equipo azul. 


```{r,eval=TRUE,echo=TRUE}

t.test(gana$diferencia_exp, pierde$diferencia_exp, alternative = "two.sided")

```


#### 4.3.2.4 Contraste de diferencia de KDA entre posiciones para el equipo ganador.

```{r,eval=TRUE,echo=TRUE}


todos_kdas<-gana['kda_top_azul']
colnames(todos_kdas)<-'kda'
todos_kdas$posicion<-as.factor('top')

variable<-gana['kda_jng_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('jng')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_mid_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('mid')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_adc_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('adc')
todos_kdas<-rbind(todos_kdas, variable)

variable<-gana['kda_sup_azul']
colnames(variable)<-'kda'
variable$posicion<-as.factor('sup')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_top_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('top')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_jng_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('jng')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_mid_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('mid')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_adc_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('adc')
todos_kdas<-rbind(todos_kdas, variable)

variable<-pierde['kda_sup_rojo']
colnames(variable)<-'kda'
variable$posicion<-as.factor('sup')
todos_kdas<-rbind(todos_kdas, variable)


kruskal.test(kda ~ posicion, data = todos_kdas)

pairwise.wilcox.test(x = todos_kdas$kda, g = todos_kdas$posicion,p.adjust.method = "holm" )
```

### 4.3.3 Regresión logística para predecir que equipo gana.

```{r,eval=TRUE,echo=TRUE}
require(caret)
require(questionr)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
require(MASS)

lol_imputed_onehot$gana_azul <- factor(lol_imputed_onehot$gana_azul, levels=c("no", "si"))


set.seed(42)
trainIndex <- createDataPartition(lol_imputed_onehot$gana_azul, p = .66, 
                                  list = FALSE, 
                                  times = 1)

Train <- lol_imputed_onehot[ trainIndex,]
Test  <- lol_imputed_onehot[-trainIndex,]


glm_train<- glm(gana_azul ~ ., data=Train, family = "binomial")

summary(glm_train)

predicciones<- predict(glm_train,Test, type="response")
predicciones <-as.factor(ifelse(predicciones>0.5,'si','no'))

confmatrix<- confusionMatrix(predicciones,Test$gana_azul )
confmatrix

require(pROC)
require(cvAUC)

# Se obtiene la predicción de los bebés sobre si tienen bajo peso o no. 
prob <- predict(glm_train,Test, type="response")

# Se obtiene un objeti de predicción que tiene información sobre los tp, tn, fp y fn. 
ROCRpred <- prediction(prob, Test$gana_azul)

# Se obtiene un objeto performance con el tpr y fpr
ROCRperf <- performance(ROCRpred, 'tpr', 'fpr')

# Se dibuja la curva roc
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2, 1.7))

# A partir del objeto prediction anterior, obtenemos la auc
auc <- performance(ROCRpred, measure = "auc")

auc <- auc@y.values[[1]]

print(paste0("El area bajo la curva ROC es de ", auc))


```

#### 4.3.3.1 Regresión logística para identificar los factores que influyen en la victoria de un equipo.

```{r,eval=TRUE,echo=TRUE}

azul<-lol_imputed_onehot %>% dplyr::select(contains("azul")| contains("exp")| contains("diff")) 
colnames(azul)<-str_replace(colnames(azul),'_azul','')
rojo<-lol_imputed_onehot %>% dplyr::select(contains("rojo")| contains("gana") | contains("exp")| contains("diff")) 
colnames(rojo)<-str_replace(colnames(rojo),'_rojo','')
colnames(rojo)<-str_replace(colnames(rojo),'_azul','')
rojo$gana<- ifelse(rojo$gana == 'si', 'no', 'si')


equipos <-rbind(azul, rojo)


set.seed(42)
trainIndex <- createDataPartition(equipos$gana, p = .66, 
                                  list = FALSE, 
                                  times = 1)

Train <- equipos[ trainIndex,]
Test  <- equipos[-trainIndex,]


glm_train<- glm(gana ~ ., data=Train, family = "binomial")

summary(glm_train)

odds.ratio(glm_train)

plot_model(glm_train, show.values = TRUE, value.offset = .1,  title = "Odds ratio for step_model")

predicciones<- predict(glm_train,Test, type="response")
predicciones <-as.factor(ifelse(predicciones>0.5,'si','no'))

confmatrix<- confusionMatrix(predicciones,Test$gana )
confmatrix

require(pROC)
require(cvAUC)

# Se obtiene la predicción de los bebés sobre si tienen bajo peso o no. 
prob <- predict(glm_train,Test, type="response")

# Se obtiene un objeti de predicción que tiene información sobre los tp, tn, fp y fn. 
ROCRpred <- prediction(prob, Test$gana)

# Se obtiene un objeto performance con el tpr y fpr
ROCRperf <- performance(ROCRpred, 'tpr', 'fpr')

# Se dibuja la curva roc
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2, 1.7))

# A partir del objeto prediction anterior, obtenemos la auc
auc <- performance(ROCRpred, measure = "auc")

auc <- auc@y.values[[1]]

print(paste0("El area bajo la curva ROC es de ", auc))

```


# 5. Representación de los resultados a partir de tablas y gráficas. 

Es importante destacar que los gráficos para las variables del dataset final, que hacen referencia a la distribución de la variables y que son útiles para el análisis estadístico descriptivo ya se han realizado en el punto 4. A continuación desarrollo los gráficos para el resto de puntos. 



